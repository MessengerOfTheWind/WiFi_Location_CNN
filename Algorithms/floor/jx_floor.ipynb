{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:57.661394Z",
     "start_time": "2025-08-20T07:11:57.507371Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 将建筑和楼层进行合并，形成新的编码\n",
    "\n",
    "\n",
    "# 1. 读取训练数据（路径请按需修改）\n",
    "train_df = pd.read_csv('C:/Users/20623/Desktop/project_code/UJIIndoorLoc-PG/UJIIndoorLoc/trainingData.csv')\n",
    "valid_df = pd.read_csv('C:/Users/20623/Desktop/project_code/UJIIndoorLoc-PG/UJIIndoorLoc/validationData.csv')\n",
    "train_df_noisy1 = pd.read_csv('../../data/train_noisy1.csv')\n",
    "\n",
    "# train_df = pd.concat([train_df, train_df_noisy1], ignore_index=True)\n",
    "# total_df = pd.concat([train_df, valid_df], ignore_index=True)\n",
    "\n",
    "# 2. 创建联合标签列（如 \"2_3\" 表示 BUILDINGID=2 且 FLOOR=3）\n",
    "train_df['location_label'] = train_df['BUILDINGID'].astype(str) + '_' + train_df['FLOOR'].astype(str)\n",
    "valid_df['location_label'] = valid_df['BUILDINGID'].astype(str) + '_' + valid_df['FLOOR'].astype(str)\n",
    "# total_df['location_label'] = total_df['BUILDINGID'].astype(str) + '_' + total_df['FLOOR'].astype(str)\n",
    "\n",
    "# 3. 将联合标签进行整数编码\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['location_label_encoded'] = label_encoder.fit_transform(train_df['location_label'])\n",
    "valid_df['location_label_encoded'] = label_encoder.fit_transform(valid_df['location_label'])\n",
    "# total_df['location_label_encoded'] = label_encoder.fit_transform(valid_df['location_label'])\n",
    "total_df = pd.concat([train_df, valid_df])\n",
    "# 4. 保存为 CSV 文件\n",
    "# train_df.to_csv('./data/processed_train.csv', index=False)\n",
    "# valid_df.to_csv('./data/processed_valid.csv', index=False)\n",
    "\n",
    "# print(\"✅ 文件已成功保存为 'processed_train.csv'\")\n",
    "# print(\"✅ 文件已成功保存为 'processed_validat.csv'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:58.978984Z",
     "start_time": "2025-08-20T07:11:57.663396Z"
    }
   },
   "id": "16d69cd613544968",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 取特征和标签\n",
    "# 训练集\n",
    "training_data = train_df[train_df.columns[:520]].to_numpy()\n",
    "training_floors = train_df['location_label_encoded'].to_numpy() # FLOOR LABELS\n",
    "# 验证集\n",
    "valid_data = valid_df[valid_df.columns[:520]].to_numpy()\n",
    "valid_floors = valid_df['location_label_encoded'].to_numpy() # FLOOR LABELS\n",
    "# 数据总和\n",
    "total_data = total_df[total_df.columns[:520]].to_numpy()\n",
    "total_floors = total_df['location_label_encoded'].to_numpy() # FLOOR LABELS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:59.056299Z",
     "start_time": "2025-08-20T07:11:58.980492Z"
    }
   },
   "id": "58e3ab1200044eb2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-104 100\n"
     ]
    }
   ],
   "source": [
    "# 数据归一化处理\n",
    "from Algorithms.utill.data_standar import normalize_rssi, normalize_coords, normalize_test_or_valid_data\n",
    "# 数据标准化,从总数居获取最大值最小值\n",
    "X_totalCo_cnn, X_min, X_max = normalize_rssi(total_data)\n",
    "print(X_min, X_max)\n",
    "# 训练集特征标准化\n",
    "training_data = normalize_test_or_valid_data(X_min, X_max, training_data)\n",
    "# 验证集特征标准化\n",
    "valid_data = normalize_test_or_valid_data(X_min, X_max, valid_data)\n",
    "# 全集\n",
    "total_data = normalize_test_or_valid_data(X_min, X_max, total_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:59.197900Z",
     "start_time": "2025-08-20T07:11:59.057302Z"
    }
   },
   "id": "9c4505d5662cfce",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 填补23*23进行CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfe6d86e9c2a44d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Augmenting data shape to fit 23x23\n",
    "training_data_aug = np.empty((len(training_data),529))\n",
    "for x in range(len(training_data)):\n",
    "    training_data_aug[x] = np.concatenate((training_data[x], np.full(shape=9,fill_value=1)))\n",
    "training_data_aug.shape\n",
    "# training_data_aug = training_data\n",
    "\n",
    "# Augmenting data shape to fit 23x23\n",
    "valid_data_aug = np.empty((len(valid_data),529))\n",
    "for x in range(len(valid_data)):\n",
    "    valid_data_aug[x] = np.concatenate((valid_data[x], np.full(shape=9,fill_value=1)))\n",
    "# valid_data_aug.shape\n",
    "# training_data_aug = training_data\n",
    "total_data_aug = np.empty((len(total_data),529))\n",
    "for x in range(len(total_data)):\n",
    "    total_data_aug[x] = np.concatenate((total_data[x], np.full(shape=9,fill_value=1)))\n",
    "# valid_data_aug.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:59.355416Z",
     "start_time": "2025-08-20T07:11:59.198902Z"
    }
   },
   "id": "a122ba93b514d631",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# total_space_ids = total_df['SPACEID'].values\n",
    "# X_temp, X_testF_cnn, y_temp, y_testF_cnn, stratify_temp, stratify_test= train_test_split(total_data_aug.reshape(len(total_data_aug),23,23), total_floors, test_size=0.2, random_state=2812,stratify=total_space_ids)\n",
    "# \n",
    "# X_trainF_cnn, X_valid_F_cnn, y_trainF_cnn, y_valid_F_cnn = train_test_split(\n",
    "#     X_temp,\n",
    "#     y_temp,\n",
    "#     test_size=1/8,   # 因为 90% * (2/9) ≈ 20%\n",
    "#     random_state=2812,\n",
    "#     stratify=stratify_temp\n",
    "# )\n",
    "\n",
    "# 准备数据\n",
    "X = total_data_aug.reshape(len(total_data_aug), 23, 23)\n",
    "y = total_floors\n",
    "z = total_df['SPACEID'].to_numpy()  # 分层标签\n",
    "\n",
    "assert len(X) == len(y) == len(z), (len(X), len(y), len(z))\n",
    "\n",
    "# 第一步：先切 20% 测试集\n",
    "X_temp, X_testF_cnn, y_temp, y_testF_cnn, stratify_temp, stratify_test = train_test_split(\n",
    "    X, y, z,\n",
    "    test_size=0.1,               # 20% → 测试\n",
    "    random_state=2812,\n",
    "    stratify=z\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T07:11:59.403520Z",
     "start_time": "2025-08-20T07:11:59.356004Z"
    }
   },
   "id": "bea5daf8a405668d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1/5 =====\n",
      "Train: (13470, 23, 23)  Valid: (3368, 23, 23)\n",
      "(Fold 1) Train cfg: dropout=0.3, lr=0.01, k=3, s=1, wd=0.001\n",
      "Epoch [1/50], Step [211/211], Loss: 2.6117\n",
      "Training Accuracy: 12.887899398803711\n",
      "Test Accuracy: 13.539192199707031\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [2/50], Step [211/211], Loss: 2.6130\n",
      "Training Accuracy: 12.887899398803711\n",
      "Test Accuracy: 13.539192199707031\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [3/50], Step [211/211], Loss: 2.6120\n",
      "Training Accuracy: 12.887899398803711\n",
      "Test Accuracy: 13.539192199707031\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [4/50], Step [211/211], Loss: 2.6110\n",
      "Training Accuracy: 12.887899398803711\n",
      "Test Accuracy: 13.539192199707031\n",
      "-> No improvement. Patience: 3/7\n",
      "------------------------------\n",
      "Epoch [5/50], Step [211/211], Loss: 0.7727\n",
      "Training Accuracy: 71.21009826660156\n",
      "Test Accuracy: 70.7244644165039\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [6/50], Step [211/211], Loss: 0.4856\n",
      "Training Accuracy: 80.49739837646484\n",
      "Test Accuracy: 79.92874145507812\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [7/50], Step [211/211], Loss: 0.5011\n",
      "Training Accuracy: 79.7550048828125\n",
      "Test Accuracy: 78.8895492553711\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [8/50], Step [211/211], Loss: 0.4555\n",
      "Training Accuracy: 80.78693389892578\n",
      "Test Accuracy: 80.6710205078125\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [9/50], Step [211/211], Loss: 0.4146\n",
      "Training Accuracy: 82.48701477050781\n",
      "Test Accuracy: 81.68052673339844\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [10/50], Step [211/211], Loss: 0.3368\n",
      "Training Accuracy: 82.31625366210938\n",
      "Test Accuracy: 81.4429931640625\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [11/50], Step [211/211], Loss: 0.3282\n",
      "Training Accuracy: 82.61321258544922\n",
      "Test Accuracy: 81.38360595703125\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [12/50], Step [211/211], Loss: 0.3309\n",
      "Training Accuracy: 83.76392364501953\n",
      "Test Accuracy: 82.77909851074219\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [13/50], Step [211/211], Loss: 0.3278\n",
      "Training Accuracy: 84.29844665527344\n",
      "Test Accuracy: 83.46199035644531\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [14/50], Step [211/211], Loss: 0.3327\n",
      "Training Accuracy: 84.26132202148438\n",
      "Test Accuracy: 83.2244644165039\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [15/50], Step [211/211], Loss: 0.2892\n",
      "Training Accuracy: 84.17965698242188\n",
      "Test Accuracy: 83.19477081298828\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [16/50], Step [211/211], Loss: 0.3124\n",
      "Training Accuracy: 85.2635498046875\n",
      "Test Accuracy: 84.02613067626953\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [17/50], Step [211/211], Loss: 0.2634\n",
      "Training Accuracy: 85.87230682373047\n",
      "Test Accuracy: 84.59026336669922\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [18/50], Step [211/211], Loss: 0.3368\n",
      "Training Accuracy: 86.08760070800781\n",
      "Test Accuracy: 85.00593566894531\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [19/50], Step [211/211], Loss: 0.2534\n",
      "Training Accuracy: 86.58500671386719\n",
      "Test Accuracy: 85.36222839355469\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [20/50], Step [211/211], Loss: 0.2630\n",
      "Training Accuracy: 87.27542877197266\n",
      "Test Accuracy: 85.68883514404297\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [21/50], Step [211/211], Loss: 0.2749\n",
      "Training Accuracy: 86.91165161132812\n",
      "Test Accuracy: 85.68883514404297\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [22/50], Step [211/211], Loss: 0.3184\n",
      "Training Accuracy: 86.40682983398438\n",
      "Test Accuracy: 84.97624969482422\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [23/50], Step [211/211], Loss: 0.3502\n",
      "Training Accuracy: 86.73348236083984\n",
      "Test Accuracy: 85.86698150634766\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [24/50], Step [211/211], Loss: 0.2877\n",
      "Training Accuracy: 87.14922332763672\n",
      "Test Accuracy: 85.86698150634766\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [25/50], Step [211/211], Loss: 0.2606\n",
      "Training Accuracy: 86.31774139404297\n",
      "Test Accuracy: 85.36222839355469\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [26/50], Step [211/211], Loss: 0.2760\n",
      "Training Accuracy: 88.11432647705078\n",
      "Test Accuracy: 86.57957458496094\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [27/50], Step [211/211], Loss: 0.2547\n",
      "Training Accuracy: 87.54268646240234\n",
      "Test Accuracy: 85.9560546875\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [28/50], Step [211/211], Loss: 0.3667\n",
      "Training Accuracy: 87.80252075195312\n",
      "Test Accuracy: 86.54988098144531\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [29/50], Step [211/211], Loss: 0.2480\n",
      "Training Accuracy: 87.55753326416016\n",
      "Test Accuracy: 86.37173461914062\n",
      "-> No improvement. Patience: 3/7\n",
      "------------------------------\n",
      "Epoch [30/50], Step [211/211], Loss: 0.3093\n",
      "Training Accuracy: 87.14922332763672\n",
      "Test Accuracy: 85.89667510986328\n",
      "-> No improvement. Patience: 4/7\n",
      "------------------------------\n",
      "Epoch [31/50], Step [211/211], Loss: 0.3405\n",
      "Training Accuracy: 87.79510498046875\n",
      "Test Accuracy: 85.98574829101562\n",
      "-> No improvement. Patience: 5/7\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_43468\\1614467198.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     61\u001B[0m                             \u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meval_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m                             \u001B[0msava_model_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msava_model_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkernel_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstride\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                             \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m                         )\n\u001B[0;32m     65\u001B[0m                         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"(Fold {fold}) Val Acc: {val_acc:.4f}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\project_code\\UJIIndoorLoc-PG\\Algorithms\\CNN.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(self, num_epochs, batch_size, eval_train, lr, patience, sava_model_name, kernel_size, stride, dropout, weight_decay)\u001B[0m\n\u001B[0;32m    135\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    136\u001B[0m                 \u001B[1;31m# backpropagation, compute gradients\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 137\u001B[1;33m                 \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    138\u001B[0m                 \u001B[1;31m# apply gradients\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m                 \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\study tools\\studytools use\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 396\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\study tools\\studytools use\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    173\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 175\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    176\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m def grad(\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import os\n",
    "from Algorithms.CNN import CNNClassifier\n",
    "\n",
    "# ===== 0) 固定测试集 =====\n",
    "X = total_data_aug.reshape(len(total_data_aug), 23, 23)\n",
    "y = total_floors\n",
    "z = total_df['SPACEID'].to_numpy()  # 分层标签（用空间/房间分层更稳）\n",
    "\n",
    "X_trainval, X_testF_cnn, y_trainval, y_testF_cnn, z_trainval, z_test = train_test_split(\n",
    "    X, y, z, test_size=0.2, random_state=2812, stratify=z\n",
    ")\n",
    "\n",
    "# ===== 1) K 折交叉验证（在 80% 训练验证集上）=====\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2812)\n",
    "\n",
    "dropout_list = [0.3]\n",
    "lr_list = [0.01]\n",
    "kernel_sizes = [3]\n",
    "strides = [1]\n",
    "weight_decays = [0.001]\n",
    "\n",
    "save_dir = \"./model\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "fold_val_scores = []\n",
    "fold_model_paths = []\n",
    "\n",
    "model_order = 82  # 你原来在用的编号\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_trainval, z_trainval), start=1):\n",
    "    X_trainF_cnn, X_valid_F_cnn = X_trainval[tr_idx], X_trainval[va_idx]\n",
    "    y_trainF_cnn, y_valid_F_cnn = y_trainval[tr_idx], y_trainval[va_idx]\n",
    "\n",
    "    print(f\"\\n===== Fold {fold}/{n_splits} =====\")\n",
    "    print(\"Train:\", X_trainF_cnn.shape, \" Valid:\", X_valid_F_cnn.shape)\n",
    "\n",
    "    best_val_acc_this_fold = -1.0\n",
    "    best_model_path_this_fold = None\n",
    "\n",
    "    # 网格可继续外套超参；示例沿用你当前单点配置\n",
    "    for val in dropout_list:\n",
    "        for lr in lr_list:\n",
    "            for kernel_size in kernel_sizes:\n",
    "                for stride in strides:\n",
    "                    for weight_decay in weight_decays:\n",
    "                        padding = 0\n",
    "                        sava_model_name = os.path.join(save_dir, f\"{model_order}_fold{fold}.pth\")\n",
    "\n",
    "                        print(f\"(Fold {fold}) Train cfg: dropout={val}, lr={lr}, k={kernel_size}, s={stride}, wd={weight_decay}\")\n",
    "                        cnn = CNNClassifier(\n",
    "                            n_classes=13, dropout=val,\n",
    "                            kernel_size=kernel_size, stride=stride, padding=padding\n",
    "                        )\n",
    "                        # 用“当前折”的 train/valid 做训练与早停\n",
    "                        cnn.fit(X_trainF_cnn, y_trainF_cnn, X_valid_F_cnn, y_valid_F_cnn)\n",
    "                        # 训练并保存当前配置的最优权重\n",
    "                        val_acc = cnn.train_model(\n",
    "                            num_epochs=50, eval_train=True, lr=lr, batch_size=64, patience=7,\n",
    "                            sava_model_name=sava_model_name, kernel_size=kernel_size, stride=stride,\n",
    "                            dropout=val, weight_decay=weight_decay\n",
    "                        )\n",
    "                        print(f\"(Fold {fold}) Val Acc: {val_acc:.4f}\")\n",
    "                        model_order += 1\n",
    "\n",
    "                        # 记录本折最佳\n",
    "                        if val_acc is not None and val_acc > best_val_acc_this_fold:\n",
    "                            best_val_acc_this_fold = val_acc\n",
    "                            best_model_path_this_fold = sava_model_name\n",
    "\n",
    "    print(f\"[Fold {fold}] Best Val Acc = {best_val_acc_this_fold:.4f} @ {best_model_path_this_fold}\")\n",
    "    fold_val_scores.append(best_val_acc_this_fold)\n",
    "    fold_model_paths.append(best_model_path_this_fold)\n",
    "\n",
    "# ===== 2) 选择“最佳折”模型，在测试集上评估 =====\n",
    "best_fold_idx = int(np.argmax(fold_val_scores))\n",
    "best_path = fold_model_paths[best_fold_idx]\n",
    "print(f\"\\n>>> Best fold = {best_fold_idx+1}, Val Acc = {fold_val_scores[best_fold_idx]:.4f}\")\n",
    "print(f\">>> Loading best fold model: {best_path}\")\n",
    "\n",
    "model = CNNClassifier(n_classes=13, kernel_size=3, stride=1, padding=0, dropout=0.3)\n",
    "model.load_model(best_path)\n",
    "# 仅为 dataloader 占位；不使用 train\n",
    "model.X_train = np.zeros_like(X_testF_cnn)\n",
    "model.Y_train = np.zeros_like(y_testF_cnn)\n",
    "model.X_test = X_testF_cnn\n",
    "model.Y_test = y_testF_cnn\n",
    "model.create_loaders(batch_size=64)\n",
    "test_acc, test_pred = model.test(model.loaders['test'])\n",
    "print(f\"[Best-fold model] Final Test Acc: {test_acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-20T08:32:34.839737Z",
     "start_time": "2025-08-20T07:12:01.292799Z"
    }
   },
   "id": "adf71640269d23ef",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "587dc24c129860bb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T06:59:52.718684Z",
     "start_time": "2025-08-19T06:59:52.712179Z"
    }
   },
   "id": "f98d4834d16ac1ca",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dropout: 0.3)\n",
      "Epoch [1/50], Step [231/231], Loss: 0.9279\n",
      "Training Accuracy: 66.3680191040039\n",
      "Test Accuracy: 66.60332489013672\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [2/50], Step [231/231], Loss: 0.4732\n",
      "Training Accuracy: 84.74173736572266\n",
      "Test Accuracy: 84.2992935180664\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [3/50], Step [231/231], Loss: 0.4313\n",
      "Training Accuracy: 85.05396270751953\n",
      "Test Accuracy: 85.24940490722656\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [4/50], Step [231/231], Loss: 0.4004\n",
      "Training Accuracy: 86.3707275390625\n",
      "Test Accuracy: 85.24940490722656\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [5/50], Step [231/231], Loss: 0.4124\n",
      "Training Accuracy: 88.73956298828125\n",
      "Test Accuracy: 87.9334945678711\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [6/50], Step [231/231], Loss: 0.3215\n",
      "Training Accuracy: 89.0382080078125\n",
      "Test Accuracy: 88.43230438232422\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [7/50], Step [231/231], Loss: 0.6114\n",
      "Training Accuracy: 89.3504409790039\n",
      "Test Accuracy: 88.31353759765625\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [8/50], Step [231/231], Loss: 0.2366\n",
      "Training Accuracy: 91.04730987548828\n",
      "Test Accuracy: 90.21377563476562\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [9/50], Step [231/231], Loss: 0.2387\n",
      "Training Accuracy: 91.90252685546875\n",
      "Test Accuracy: 91.33016204833984\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [10/50], Step [231/231], Loss: 0.1197\n",
      "Training Accuracy: 93.97270965576172\n",
      "Test Accuracy: 93.15914154052734\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [11/50], Step [231/231], Loss: 0.1658\n",
      "Training Accuracy: 93.73515319824219\n",
      "Test Accuracy: 93.34916687011719\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [12/50], Step [231/231], Loss: 0.0894\n",
      "Training Accuracy: 95.86642456054688\n",
      "Test Accuracy: 94.96437072753906\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [13/50], Step [231/231], Loss: 0.1245\n",
      "Training Accuracy: 96.28724670410156\n",
      "Test Accuracy: 95.58194732666016\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [14/50], Step [231/231], Loss: 0.0415\n",
      "Training Accuracy: 97.07459259033203\n",
      "Test Accuracy: 96.15202331542969\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [15/50], Step [231/231], Loss: 0.0561\n",
      "Training Accuracy: 95.91393280029297\n",
      "Test Accuracy: 95.32066345214844\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [16/50], Step [231/231], Loss: 0.0497\n",
      "Training Accuracy: 94.90938568115234\n",
      "Test Accuracy: 94.48931121826172\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [17/50], Step [231/231], Loss: 0.0615\n",
      "Training Accuracy: 97.05422973632812\n",
      "Test Accuracy: 96.24703216552734\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [18/50], Step [231/231], Loss: 0.0603\n",
      "Training Accuracy: 96.74201202392578\n",
      "Test Accuracy: 96.22327423095703\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [19/50], Step [231/231], Loss: 0.0796\n",
      "Training Accuracy: 96.9931411743164\n",
      "Test Accuracy: 96.34204864501953\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [20/50], Step [231/231], Loss: 0.0817\n",
      "Training Accuracy: 97.4546890258789\n",
      "Test Accuracy: 96.3895492553711\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [21/50], Step [231/231], Loss: 0.0704\n",
      "Training Accuracy: 97.18997955322266\n",
      "Test Accuracy: 96.43705749511719\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [22/50], Step [231/231], Loss: 0.0367\n",
      "Training Accuracy: 96.19222259521484\n",
      "Test Accuracy: 94.98812866210938\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [23/50], Step [231/231], Loss: 0.0251\n",
      "Training Accuracy: 97.63795471191406\n",
      "Test Accuracy: 96.50831604003906\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [24/50], Step [231/231], Loss: 0.0155\n",
      "Training Accuracy: 97.3868179321289\n",
      "Test Accuracy: 96.62708282470703\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [25/50], Step [231/231], Loss: 0.0944\n",
      "Training Accuracy: 97.90266418457031\n",
      "Test Accuracy: 97.10213470458984\n",
      "-> Model improved. Saving \n",
      "------------------------------\n",
      "Epoch [26/50], Step [231/231], Loss: 0.0500\n",
      "Training Accuracy: 97.10174560546875\n",
      "Test Accuracy: 96.0094985961914\n",
      "-> No improvement. Patience: 1/7\n",
      "------------------------------\n",
      "Epoch [27/50], Step [231/231], Loss: 0.0158\n",
      "Training Accuracy: 97.42076110839844\n",
      "Test Accuracy: 96.50831604003906\n",
      "-> No improvement. Patience: 2/7\n",
      "------------------------------\n",
      "Epoch [28/50], Step [231/231], Loss: 0.0236\n",
      "Training Accuracy: 97.63116455078125\n",
      "Test Accuracy: 96.53206634521484\n",
      "-> No improvement. Patience: 3/7\n",
      "------------------------------\n",
      "Epoch [29/50], Step [231/231], Loss: 0.0235\n",
      "Training Accuracy: 95.69673156738281\n",
      "Test Accuracy: 94.98812866210938\n",
      "-> No improvement. Patience: 4/7\n",
      "------------------------------\n",
      "Epoch [30/50], Step [231/231], Loss: 0.0113\n",
      "Training Accuracy: 97.7465591430664\n",
      "Test Accuracy: 96.79335021972656\n",
      "-> No improvement. Patience: 5/7\n",
      "------------------------------\n",
      "Epoch [31/50], Step [231/231], Loss: 0.0362\n",
      "Training Accuracy: 97.7397689819336\n",
      "Test Accuracy: 96.9596176147461\n",
      "-> No improvement. Patience: 6/7\n",
      "------------------------------\n",
      "Epoch [32/50], Step [231/231], Loss: 0.0350\n",
      "Training Accuracy: 97.97054290771484\n",
      "Test Accuracy: 96.91211700439453\n",
      "-> No improvement. Patience: 7/7\n",
      "Early stopping triggered!\n",
      "parameter sava...epoch:31 batch_size64 lr:0.01 kernel_size3 stride:1 train_acc:97.90266418457031 test_acc:97.10213470458984\n",
      "Best model parameters loaded: ./model/82test.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Floor Classifier\n",
    "# dropout = [0.3]\n",
    "# lrs = [0.01]\n",
    "# kernel_sizes = [3]\n",
    "# strides = [1]\n",
    "# model_order = 82\n",
    "# weight_decays = [0.001]\n",
    "# for val in dropout:\n",
    "#     for lr in lrs:\n",
    "#         for kernel_size in kernel_sizes:\n",
    "#             for stride in strides:\n",
    "#                 for weight_decay in weight_decays:\n",
    "#                     # padding = compute_padding(kernel_size, stride)\n",
    "#                     padding = 0\n",
    "#                     print(f'(Dropout: {val})')\n",
    "#                     cnn = CNNClassifier(n_classes=13, dropout=val, kernel_size=kernel_size, stride=stride, padding=padding) \n",
    "#                     cnn.fit(X_trainF_cnn, y_trainF_cnn, X_testF_cnn, y_testF_cnn)\n",
    "#                     cnn.train_model(num_epochs=50,eval_train=True, lr=lr, batch_size=64, patience = 7, sava_model_name=\"./model/\"+str(model_order)+\"test.pth\", kernel_size = kernel_size, stride = stride, dropout=val, weight_decay=weight_decay)\n",
    "#                     model_order += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T13:30:58.104290Z",
     "start_time": "2025-08-19T12:03:12.732909Z"
    }
   },
   "id": "74e23fa9a6b97038",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-18T14:20:03.478280Z",
     "start_time": "2025-08-18T14:20:03.463270Z"
    }
   },
   "id": "1d04e982205bfccb",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid collection: 96.86460876464844 \n"
     ]
    }
   ],
   "source": [
    "# # 验证模型效果\n",
    "# from Algorithms.CNN import CNNRegressor\n",
    "# import numpy as np\n",
    "# # 假设你的模型是 CNNRegressor，有两个目标值\n",
    "# dropout = [0.3]\n",
    "# lrs = [0.001]\n",
    "# kernel_sizes = [3]\n",
    "# strides = [1]\n",
    "# model_order = 82\n",
    "# weight_decays = [0.0001]\n",
    "# # 加载保存的权重\n",
    "# for val in dropout:\n",
    "#     for lr in lrs:\n",
    "#         for kernel_size in kernel_sizes:\n",
    "#             for stride in strides:\n",
    "#                 for weight_decay in weight_decays:\n",
    "#                     sava_model_name=\"./model/\"+str(model_order)+\"test.pth\"\n",
    "#                     padding = 0\n",
    "#                     model = CNNClassifier(n_classes=13, kernel_size=kernel_size, stride=stride, padding=padding, dropout=val)\n",
    "#                     model.load_model(sava_model_name)\n",
    "#                     model.X_train = np.zeros_like(X_valid_F_cnn)  # 随便补一个假的训练集占位，不会用到\n",
    "#                     model.Y_train = np.zeros_like(y_valid_F_cnn)\n",
    "#                     # 注意：还需要加载相应的数据\n",
    "#                     model.X_test = X_valid_F_cnn\n",
    "#                     model.Y_test = y_valid_F_cnn\n",
    "#                     # model.X_train = None\n",
    "#                     # model.y_train = None\n",
    "#                     model.create_loaders(batch_size=64)\n",
    "#                     correct,_ = model.test(model.loaders['test'])\n",
    "#     \n",
    "#                     print(f\"valid collection: {correct} \")\n",
    "#                     model_order += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T15:44:27.291949Z",
     "start_time": "2025-08-19T15:44:21.495613Z"
    }
   },
   "id": "4623036e90f6f732",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-18T14:20:08.051001Z",
     "start_time": "2025-08-18T14:20:08.051001Z"
    }
   },
   "id": "d5c15e5b22805480",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
