(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0155
26.017215935875058
38.22474121132391
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0079
13.035601516386242
19.02997494703385
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0078
10.077322397020176
14.937389445851723
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0072
9.07543183513363
13.60832297106622
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0071
8.796491198112868
13.32365800893721
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0071
8.607672127999813
13.036994783176189
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0072
8.049643210768691
12.225560140706142
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0067
7.547488356625949
11.521708796741914
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0059
8.215752184838859
12.436398302990668
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0059
7.940448639876235
12.083879514533674
→ No improvement. Patience: 2/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0071
7.959020106367553
12.05399743061141
→ No improvement. Patience: 3/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0066
9.093034001919657
13.6798841433535
→ No improvement. Patience: 4/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0059
9.493843178049097
14.241179356404517
→ No improvement. Patience: 5/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0057
8.433775202115307
12.753062314170366
→ No improvement. Patience: 6/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0055
9.293881892123254
13.965989704591765
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:14 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:7.547488356625949 test_acc:11.521708796741914
Best model parameters loaded: ./model/1lo.pth
Best model parameters loaded../model/1lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0111
16.392598846113827
24.302375413824354
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0081
8.671111554950537
12.960638775402936
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0069
9.344030097679758
14.028421518960737
→ No improvement. Patience: 1/7
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0063
8.837483002388966
13.278908755304025
→ No improvement. Patience: 2/7
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0050
7.588005781293117
11.605520074473322
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0050
7.069891726689761
10.774183931036621
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0048
8.42665288097516
12.677912318834352
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0046
5.8810787670520845
9.195164477812126
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0045
6.147501777944429
9.62798760730596
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0041
6.366259035948545
9.972683014955118
→ No improvement. Patience: 2/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0038
7.77280182706894
11.84702282218873
→ No improvement. Patience: 3/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0037
6.1903810956801175
9.641436597408518
→ No improvement. Patience: 4/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0039
5.719267880797079
8.98824186528673
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0040
5.557057025656186
8.888602525369736
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0035
5.246944009140799
8.47122995850821
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0038
6.415596374278905
9.998142501596474
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0037
4.977483593587285
8.143589306295233
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0037
5.23991624750434
8.515050569275797
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0036
5.2821905579311785
8.602358519706723
→ No improvement. Patience: 2/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
6.641062473039259
10.527400377835745
→ No improvement. Patience: 3/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0034
5.032571643305507
8.246721518287107
→ No improvement. Patience: 4/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0033
4.712472371392169
7.795618681298063
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0034
4.832802798620698
7.916219602919011
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0031
4.570773347020112
7.586094839069442
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0030
4.886687349358883
7.9743846081560195
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0032
4.83160867090933
7.954557432016642
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0032
4.958623175510033
8.113318586655934
→ No improvement. Patience: 3/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0032
4.5716069761750155
7.674429014778756
→ No improvement. Patience: 4/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0033
4.824932957639714
7.998596240728431
→ No improvement. Patience: 5/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0029
5.239622779656479
8.384861376686576
→ No improvement. Patience: 6/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0027
5.396119457561531
8.563922772976305
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:30 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:4.570773347020112 test_acc:7.586094839069442
Best model parameters loaded: ./model/2lo.pth
Best model parameters loaded../model/2lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0154
15.349487129574214
22.99777698694509
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0097
9.827001941327214
14.777273073163704
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0092
8.13260683488503
12.266440113425189
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0080
7.2964089805561425
11.136040638603154
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0069
6.662467995971702
10.32764742609664
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0068
6.191817468117288
9.640904683097324
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0061
6.387269366516827
9.975033836330118
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0063
6.0238782383529035
9.533126710197463
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0054
5.64342471174153
9.014667886817342
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0051
6.540116092695383
10.270435798827695
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0045
6.075904988231923
9.607814614387893
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0043
5.799299999321715
9.147052102657206
→ No improvement. Patience: 3/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0042
5.556087058124757
8.816485949062317
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0037
7.1903556256451875
11.008448594647662
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0037
6.160517243859992
9.690258192007446
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0040
6.6192413952409535
10.296046593821364
→ No improvement. Patience: 3/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0041
5.905651798638985
9.311831355209788
→ No improvement. Patience: 4/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0041
6.411831367872192
10.030949407485734
→ No improvement. Patience: 5/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0039
5.300146833851193
8.371173067699912
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0040
5.305483540857577
8.425071658160334
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0037
5.116553277586054
8.200107323684778
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0033
4.992938899796315
8.02719534477051
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0034
7.747416680498032
11.980554106613093
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0032
4.8271381133795535
7.792527228798467
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0034
5.320013491741499
8.498793919569483
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0037
7.203133049557591
11.084417874048121
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0033
5.241995970018385
8.362548863965191
→ No improvement. Patience: 3/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0033
5.266947460672054
8.357782996786261
→ No improvement. Patience: 4/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0032
6.7868773814685435
10.377174355247272
→ No improvement. Patience: 5/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0033
4.537043787426951
7.310186371308334
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0034
5.05163932109981
7.999976931099857
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0034
5.402128123241466
8.581164393143512
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0032
5.425353985901468
8.529143247690177
→ No improvement. Patience: 3/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0031
4.662950679616575
7.495607366275132
→ No improvement. Patience: 4/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0030
5.067619749455713
8.110808405675689
→ No improvement. Patience: 5/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0030
6.244250296959314
9.733946330514215
→ No improvement. Patience: 6/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0029
5.912952487042666
9.262069414238143
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:36 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:4.537043787426951 test_acc:7.310186371308334
Best model parameters loaded: ./model/3lo.pth
Best model parameters loaded../model/3lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0148
42.48184558209155
62.163450292302514
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0068
10.796706140352638
15.936351148684846
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0061
9.708507948537214
14.35519269042278
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0070
8.742956046311072
12.955932748273208
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0073
8.435901330018766
12.55893756945523
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0071
8.711254328677997
12.931718516011212
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0065
7.652472693661152
11.502711196437076
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0064
7.45211898742618
11.228415311324143
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0062
7.190757311387148
10.890581651780833
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0056
6.788636189318627
10.373774970498106
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0053
6.598136726552176
10.157799221504535
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0051
6.509198257241144
10.013964335472766
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0052
7.8479334472296225
11.89705389871806
→ No improvement. Patience: 1/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0049
7.530960841925875
11.433503875070665
→ No improvement. Patience: 2/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0048
7.256150195299846
11.060628031285102
→ No improvement. Patience: 3/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0048
7.604550485194134
11.535055585233755
→ No improvement. Patience: 4/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0045
6.974644236706158
10.702139523249192
→ No improvement. Patience: 5/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0045
7.093138613851633
10.849626588794012
→ No improvement. Patience: 6/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0043
6.1613480972987755
9.541453581892249
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0041
6.070130851271693
9.416506211981456
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0040
6.1484424019144335
9.538445215600468
→ No improvement. Patience: 1/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0040
6.4042305920118965
9.90751031254644
→ No improvement. Patience: 2/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0040
6.312100682791691
9.756353797599717
→ No improvement. Patience: 3/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0045
5.917301263336438
9.304225021930076
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0040
8.635032874436252
13.053453870954373
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0042
6.256877184825858
9.769517589158681
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0039
6.201677874355278
9.71342677941047
→ No improvement. Patience: 3/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0039
6.734199364162633
10.4187038697897
→ No improvement. Patience: 4/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0037
6.33962301962996
9.891670470034398
→ No improvement. Patience: 5/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0036
6.400114552292622
9.977884826451598
→ No improvement. Patience: 6/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0036
6.150836603526476
9.68396465315339
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:30 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:5.917301263336438 test_acc:9.304225021930076
Best model parameters loaded: ./model/4lo.pth
Best model parameters loaded../model/4lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0154
15.618446058115081
23.269901941921525
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0073
9.678246596705684
14.565052780671817
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0073
7.885864397140477
12.04499186301808
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0068
7.325680680995161
11.259146075450213
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0057
7.659036941310013
11.76172969570045
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0052
7.490841696588048
11.552664501655926
→ No improvement. Patience: 2/7
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0048
6.924465908474081
10.745671766659072
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0047
6.823988922138742
10.607794233106057
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0043
6.803394231261623
10.597747938500943
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0040
6.252905908735742
9.80608880138457
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0038
6.521471975377023
10.225079274072641
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0043
5.933612632226936
9.451382932044707
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0042
5.592498575420207
8.937853993501607
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0040
5.277476064413334
8.519021778225826
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0046
5.707901938746106
9.046292541176355
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0039
5.467437080530533
8.702381358485612
→ No improvement. Patience: 2/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0036
5.515015192430901
8.792646864216001
→ No improvement. Patience: 3/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0034
4.910990421007247
8.010395031653916
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0036
4.9241885793955875
8.039145474142225
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0034
4.962299884686457
8.028975736055635
→ No improvement. Patience: 2/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0031
4.737577942013939
7.833758992368491
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0030
5.024125345210319
8.186840700138681
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0032
4.578560294183922
7.591863181612921
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0029
4.574000694770015
7.55202532022626
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0028
4.839127398341592
7.9241860920740725
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0029
5.289514278085658
8.537348307891797
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0031
4.840192161156905
7.933348551333559
→ No improvement. Patience: 3/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0031
5.025477155553757
8.151644359030255
→ No improvement. Patience: 4/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0033
5.096287766647324
8.24949277659217
→ No improvement. Patience: 5/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0032
6.092912573441106
9.620484786492314
→ No improvement. Patience: 6/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0031
7.026336032301782
10.90103456210206
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:30 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:4.574000694770015 test_acc:7.55202532022626
Best model parameters loaded: ./model/5lo.pth
Best model parameters loaded../model/5lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0126
14.430710198848603
21.671558701828427
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0083
9.470393782381585
14.399357545636562
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0077
7.782977457496824
11.822621806340587
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0071
6.670215589758179
10.278448155914655
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0067
6.016673827913943
9.404862164487671
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0062
5.912027801015201
9.260890824590561
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0059
5.589745005576354
8.855398596671789
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0056
5.627548056382058
8.906696652203117
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0048
5.8549813459355775
9.272564512681855
→ No improvement. Patience: 2/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0044
5.157689086020858
8.302593167224266
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0041
5.395421047944928
8.664126082232418
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0039
5.837558133939212
9.232626229274105
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0038
4.8806441669228295
7.956842723144251
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0034
4.5001342939930264
7.405293983490508
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0033
4.468358075119825
7.385524647646184
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0032
4.313773994685882
7.15197919972846
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0036
4.214176457582696
6.971441477298967
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0034
6.524342096016196
10.002946160270067
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0029
6.210164681241085
9.608123916246564
→ No improvement. Patience: 2/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0027
7.739793457621433
11.779900480392149
→ No improvement. Patience: 3/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0033
4.316921076819356
7.098373539614433
→ No improvement. Patience: 4/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0031
4.297741723285791
7.093513651977771
→ No improvement. Patience: 5/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0030
4.1040544192386665
6.8652831674703885
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0030
4.065504288178365
6.831813006573153
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0029
5.087523764947979
8.109264512680358
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0027
3.9129418384109425
6.597987002487421
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0028
3.858962143544264
6.4516475740733075
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0026
3.79721288307296
6.439272322955634
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0026
3.797184855453371
6.397871802917193
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0027
4.20082710927684
6.890663142488734
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0027
4.050416519500677
6.724503591525927
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0030
4.123438057990638
6.871422453995055
→ No improvement. Patience: 3/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0027
4.1577616789243015
6.836667797903999
→ No improvement. Patience: 4/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0025
4.249204406799337
6.906511259720178
→ No improvement. Patience: 5/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0025
3.980107648562047
6.60892087250481
→ No improvement. Patience: 6/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0026
3.970605308763543
6.564337535546703
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:35 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:3.797184855453371 test_acc:6.397871802917193
Best model parameters loaded: ./model/6lo.pth
Best model parameters loaded../model/6lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0220
30.392551539339248
44.675369167297006
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0107
14.86710682652609
21.66840063483845
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0085
12.337065897307525
18.141933775910818
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0074
10.549958685773165
15.64839451166992
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0067
9.744754826540568
14.477558357609913
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0064
9.15554584861211
13.62841877588533
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0061
8.743948295140404
13.05873021666339
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0058
8.400283069885484
12.585171547346851
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0055
8.172920920861866
12.267102858363092
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0054
7.867833576068326
11.8423979259018
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0052
7.628618398790622
11.496768951733873
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0050
7.347522166833424
11.091794001375064
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0049
7.149271982506401
10.801029842804477
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0047
7.059125257860905
10.711746549557311
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0046
6.9333591050916805
10.555746997305777
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0044
6.74327974726255
10.281757910079548
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
6.6227843650885045
10.124916133291881
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0043
6.586954162020549
10.093254519635874
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0043
6.546502646688059
10.023443588289993
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
6.55908306486802
10.075346590031264
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0042
6.596374325356107
10.122127184453811
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0041
6.542983359095206
10.037270920853336
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0040
6.45609936357203
9.920713575308413
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0040
6.442788491485374
9.95708080585912
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0040
6.365408726504444
9.839199749981763
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0040
6.411128720115562
9.908047621026231
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0038
6.3040736398277675
9.793781218114109
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0039
6.1557122139410705
9.584167993917257
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0038
6.099947798585325
9.520817590378776
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0038
6.052620810658639
9.48121078668863
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0039
6.070141939902839
9.507087006619521
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0037
6.335372177905295
9.843652463603297
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0037
6.3406698369505765
9.881500594709337
→ No improvement. Patience: 3/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0037
6.180244902831299
9.662890085040633
→ No improvement. Patience: 4/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0036
6.406049497112429
9.974115378332892
→ No improvement. Patience: 5/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0036
6.167094840230786
9.658056678717513
→ No improvement. Patience: 6/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0035
6.125625496418892
9.616198258795126
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:36 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:6.052620810658639 test_acc:9.48121078668863
Best model parameters loaded: ./model/7lo.pth
Best model parameters loaded../model/7lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0245
30.808852909425937
45.7442614052871
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0115
15.087602837662113
22.280349443006614
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0093
12.338622107837972
18.268091694270566
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0075
10.674132697236223
15.971270924066005
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0066
9.597720542316303
14.387634204463623
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0062
8.887642249695258
13.349996086808853
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0059
8.610213035233945
12.90950745391715
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0058
8.354047938865806
12.512765511533612
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0054
7.9668460946024195
11.967627451677481
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0051
7.565154704748607
11.388900244628395
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0047
7.433989801801151
11.207692471607619
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0045
7.202840281264161
10.87777114653972
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0043
6.950124540199407
10.530256551948291
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0042
6.813407179761213
10.351863248733594
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0041
6.435405519423662
9.861384662373734
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0040
6.233143493842086
9.602112477788351
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0040
5.967954009679468
9.25294503441273
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0039
5.8194725244468675
9.07680214834576
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0039
5.519357441163899
8.675391633441718
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0038
5.433596054142325
8.571739544084629
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0039
5.236699787033023
8.35249400492011
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0040
5.240093648477508
8.378138811486378
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0040
5.334340710026647
8.548673231480027
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0039
5.568435598165527
8.893653987286546
→ No improvement. Patience: 3/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0038
6.141798243240951
9.680643081281753
→ No improvement. Patience: 4/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0036
5.924197863942414
9.381776991295437
→ No improvement. Patience: 5/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0035
5.5998125381172095
8.941031277024923
→ No improvement. Patience: 6/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0035
5.15596584539114
8.350495485455045
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0034
4.758917831075953
7.804797830403909
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0032
4.493205927879418
7.456456879496037
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0032
4.48875385567013
7.439829141653776
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0031
4.432667139478271
7.361725135318318
→ Model improved. Saving...
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0031
4.3522602853328545
7.26905651858759
→ Model improved. Saving...
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0030
4.321320767975879
7.22494027156471
→ Model improved. Saving...
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0030
4.311569960940734
7.216955439317269
→ Model improved. Saving...
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0030
4.281651985637989
7.1983036238698
→ Model improved. Saving...
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0029
4.305335469252996
7.213179007140764
→ No improvement. Patience: 1/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0030
4.192840731505818
7.088769886463027
→ Model improved. Saving...
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0029
4.161827409131011
7.059290696949728
→ Model improved. Saving...
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0031
4.269823204569344
7.211550760291696
→ No improvement. Patience: 1/7
------------------------------
Epoch [41/100], Step [499/499], Loss: 0.0032
4.818786347993441
7.933302564483255
→ No improvement. Patience: 2/7
------------------------------
Epoch [42/100], Step [499/499], Loss: 0.0031
6.276846687756989
9.831025172683784
→ No improvement. Patience: 3/7
------------------------------
Epoch [43/100], Step [499/499], Loss: 0.0029
5.2601492058754875
8.498648161522613
→ No improvement. Patience: 4/7
------------------------------
Epoch [44/100], Step [499/499], Loss: 0.0029
4.9236765609654265
8.05742876200507
→ No improvement. Patience: 5/7
------------------------------
Epoch [45/100], Step [499/499], Loss: 0.0029
5.167061275757503
8.379943262923437
→ No improvement. Patience: 6/7
------------------------------
Epoch [46/100], Step [499/499], Loss: 0.0029
5.07785374794384
8.243530766563655
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:45 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:4.161827409131011 test_acc:7.059290696949728
Best model parameters loaded: ./model/8lo.pth
Best model parameters loaded../model/8lo.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0207
21.316522220201314
31.648355939242133
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0094
12.195483398611794
18.222753295658652
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0076
9.637170371833559
14.449556555434716
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0069
8.403701497970644
12.61595371256987
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0063
7.783326963591686
11.72423062888013
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0060
7.224051429068142
10.931101540632529
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0057
7.038151515577991
10.709327301781947
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0054
6.7673815623197395
10.343336839341372
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0052
6.510808851333024
10.008880172723044
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0050
6.147406203847233
9.52341366095137
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0049
6.006867100891574
9.34209390095936
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0047
5.741123107747777
8.998276526842893
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0046
5.496848878925652
8.673254401609542
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0044
5.158176631885982
8.21047588852583
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0043
4.9751250198245645
7.964339763795966
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0042
4.889273464061961
7.847955736274001
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0041
4.696693847887568
7.586048893115392
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0040
4.520996868884299
7.34359376094783
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0039
4.529420587098671
7.369205442174078
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0038
4.329739353054895
7.126607270544543
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0037
4.2448178560678365
6.989759486196997
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0037
4.276289851629623
7.069390928383143
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0036
4.260854278793357
7.038763924784065
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0036
4.148114661799023
6.877706407598162
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0035
3.8493544322032216
6.522371385983702
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0034
3.8275784537787496
6.482262733572728
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0033
3.8650491394859277
6.551439383005884
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0033
3.7255617606824765
6.368515212219889
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0032
3.689639635805235
6.327561509959668
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0033
3.736662928208855
6.39292125377686
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0032
3.576168130696024
6.15196153835513
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0032
3.7567648479935185
6.4055343250964505
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0032
4.122257515078674
6.92433621389317
→ No improvement. Patience: 2/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0032
4.1096454201266575
6.889645403836344
→ No improvement. Patience: 3/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0031
4.091501911626618
6.8651142989535545
→ No improvement. Patience: 4/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0031
4.386223447225968
7.25894660926208
→ No improvement. Patience: 5/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0031
4.255271427518195
7.105819807533169
→ No improvement. Patience: 6/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0031
4.527955491080541
7.454239758120339
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:37 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:3.576168130696024 test_acc:6.15196153835513
Best model parameters loaded: ./model/9lo.pth
Best model parameters loaded../model/9lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0250
47.24801268091721
69.44600229455901
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0076
12.490069029628698
18.561449655867627
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0066
10.261859530668335
15.200058985962801
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0065
10.003669677901868
14.756190187954825
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0064
9.661962473526046
14.28160556388139
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0066
8.373481778876467
12.450620054046828
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0064
7.807187085443431
11.753103221805738
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0065
7.5953931713532485
11.533180490004831
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0061
7.943746953947362
12.009267038051602
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0057
7.887303736109702
11.92980173899675
→ No improvement. Patience: 2/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0056
8.021092750172082
12.18601846628671
→ No improvement. Patience: 3/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0059
7.423693712922663
11.358525056688116
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0054
7.849023783854874
11.998553294025264
→ No improvement. Patience: 1/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0053
7.318784362747509
11.2867966623757
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0052
7.06496035096918
10.937808407599753
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0049
7.082532826344085
10.87138846107924
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0048
7.5830077628013175
11.552651697673344
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0045
7.031708958789445
10.810853243980146
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0045
7.411465714614848
11.33865969794867
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0044
7.296618643152061
11.151365239440555
→ No improvement. Patience: 2/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0042
6.911706116778805
10.633133505036573
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0042
6.557098118190971
10.24931587188159
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0042
6.2452944098147904
9.803166052706366
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0041
6.241489178385249
9.798116495982606
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0041
5.8637768227770275
9.319907924940225
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0041
5.814922605216063
9.25034102163431
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0042
5.728843861474577
9.153850942590658
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0040
5.727007007246726
9.156518133091458
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0039
5.786291323134071
9.238743793489244
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0039
5.692138953201598
9.113613154250455
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0039
7.429370895669959
11.443488404540542
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0043
6.54478524934843
10.2018427259791
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0041
6.006870680197007
9.510203410199281
→ No improvement. Patience: 3/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0038
6.097166232597574
9.608335686997828
→ No improvement. Patience: 4/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0037
6.335345878419544
9.977833875838295
→ No improvement. Patience: 5/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0039
6.042509396415795
9.579137386096743
→ No improvement. Patience: 6/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0037
5.862391315078803
9.356827479984084
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:36 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:5.692138953201598 test_acc:9.113613154250455
Best model parameters loaded: ./model/10lo.pth
Best model parameters loaded../model/10lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0147
14.703787348988463
21.708323171605027
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0071
10.020758194651092
14.961972759833708
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0059
8.668951621132644
13.176996807287992
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0055
7.20649812803267
11.027749736172101
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0054
7.709820177407357
11.789967468885575
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0047
6.640935483529795
10.316391384012881
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0044
6.025219775821526
9.463230409715274
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0041
5.4460484254606
8.707829620826027
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0043
5.47295985563162
8.66533847080586
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0037
5.829521879560101
9.241902394351495
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0037
6.940522778882447
10.735806942546986
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0037
5.8819040678112895
9.363302310687526
→ No improvement. Patience: 3/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0040
5.711822541235505
9.137061505294131
→ No improvement. Patience: 4/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0038
6.81996468084625
10.654384982897465
→ No improvement. Patience: 5/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0035
6.401252906099466
10.129956368901942
→ No improvement. Patience: 6/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0031
6.7414233267006916
10.59990867232483
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:15 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:5.47295985563162 test_acc:8.66533847080586
Best model parameters loaded: ./model/11lo.pth
Best model parameters loaded../model/11lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0154
16.592461275923093
24.86855328515886
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0075
8.69720512237122
13.092939460658043
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0064
7.051695581813436
10.769134509215084
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0055
7.652867838866213
11.663664137390976
→ No improvement. Patience: 1/7
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0051
8.38440441658488
12.673301588737015
→ No improvement. Patience: 2/7
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0049
7.604827298862734
11.604673350744847
→ No improvement. Patience: 3/7
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0044
7.967491017704054
12.14909849080687
→ No improvement. Patience: 4/7
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0044
7.012634381435857
10.743220469291686
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0042
7.84145962731837
11.930230579297207
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0042
5.535862024721297
8.731954288752004
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0040
9.860416570001941
14.898558149920374
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0052
5.992138268485182
9.423576688090483
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0039
7.249021016021074
11.183621866668512
→ No improvement. Patience: 3/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0040
7.930022816097794
12.155298073253979
→ No improvement. Patience: 4/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0039
5.649047079318194
9.019967970411873
→ No improvement. Patience: 5/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0036
5.480491124612053
8.714628170298731
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0034
5.20046942397079
8.281344684784672
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0035
5.209108494360757
8.409231264728215
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0036
4.717914701770698
7.71083336513507
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0036
5.187405223505861
8.297463438337779
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0030
6.195518651023932
9.677143054670825
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0028
5.785035426962579
9.103327849472683
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0031
4.7357269390540635
7.638580335517477
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0034
5.536214591515731
8.80102738112178
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0034
4.541135812167189
7.412389827645981
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0033
5.053198781553969
8.051062218732353
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0031
4.48905956030325
7.318620773783254
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0029
4.942642039852838
7.897471156868798
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0032
7.316820339830434
11.115872414358002
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0030
5.976107774229812
9.309981581810833
→ No improvement. Patience: 3/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0032
5.508585458063301
8.5365228543006
→ No improvement. Patience: 4/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0029
5.468304053503208
8.56700848047365
→ No improvement. Patience: 5/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0030
4.560510269558139
7.407279963526623
→ No improvement. Patience: 6/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0030
5.224373480674025
8.361270276340974
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:33 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:4.48905956030325 test_acc:7.318620773783254
Best model parameters loaded: ./model/12lo.pth
Best model parameters loaded../model/12lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0167
57.876027299567234
84.82141883960513
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0078
11.58666937547839
17.055571243196425
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0063
9.415377616477201
14.02781501928774
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0062
9.527732819082663
14.213710467688946
→ No improvement. Patience: 1/7
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0066
9.51296631697159
14.220357100488743
→ No improvement. Patience: 2/7
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0071
8.672857360964187
13.06832055090457
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0068
7.328241237946058
11.12313966627763
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0059
7.085266767570058
10.788291855852936
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0054
7.233113578672242
10.979632223167417
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0054
7.623292509628622
11.492846390367484
→ No improvement. Patience: 2/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0049
7.529716741424058
11.408555801097046
→ No improvement. Patience: 3/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0050
7.121632207940768
10.880378129526234
→ No improvement. Patience: 4/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0051
6.863931679947875
10.50462578862832
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0048
8.628502678756671
13.05738483569695
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0046
8.033548969272479
12.264425007811761
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0044
6.810588973882212
10.530915554992152
→ No improvement. Patience: 3/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
6.434238946249153
10.071504496099685
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0045
6.6659218232365225
10.297006141321905
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0042
6.392039769197778
9.935329411025275
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0041
5.995030379147746
9.448965064518823
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0039
5.993891517054184
9.419010243206552
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0039
6.0628824121462666
9.518339829879118
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0039
5.964386089757834
9.393126083382969
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0038
5.783066077005452
9.195025920656594
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0037
6.266348456852981
9.888225544292252
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0037
6.295869299428936
9.923681644051756
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0037
6.43773125936233
10.136970193252516
→ No improvement. Patience: 3/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0036
6.123900075174953
9.683514697395198
→ No improvement. Patience: 4/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0036
6.442738667316682
10.108736834737645
→ No improvement. Patience: 5/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0035
6.679455628877771
10.429745634050626
→ No improvement. Patience: 6/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0035
7.237532626697819
11.2232936363218
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:30 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:5.783066077005452 test_acc:9.195025920656594
Best model parameters loaded: ./model/13lo.pth
Best model parameters loaded../model/13lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0250
32.400873503943416
47.80147320784053
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0097
12.487432361702792
18.515586219140662
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0086
10.513193401502164
15.764245568516788
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0077
7.932225290986377
12.105927433543988
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0065
7.072903432236661
10.935112038972926
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0053
6.7483628141767955
10.499861324922792
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0050
6.749879261987551
10.464671070235797
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0046
6.7902940037025905
10.505244944306645
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0043
7.200152689586729
11.092516983643602
→ No improvement. Patience: 2/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0042
6.600694741697119
10.233538709882911
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0040
6.792178670120953
10.464278590106435
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0038
6.914811547483485
10.634735114712878
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0043
6.173038296682833
9.591084574174609
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0040
8.748811641641158
13.182277864072798
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0042
5.972528110428903
9.322755273459515
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0039
5.724514042264045
8.95357931122922
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0039
5.2613542740023
8.339806501166068
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0035
5.321642360808771
8.407732625966092
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0034
5.0911405900280835
8.109653911987374
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0031
6.3022675301881455
9.765562940010364
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0033
5.0524084345614835
8.074485332699465
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0032
4.908322509975953
7.857112009277061
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0031
5.0501486852052935
7.984175489571249
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0031
5.579101599343546
8.712529901843222
→ No improvement. Patience: 2/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0029
6.651022240327122
10.253846938429042
→ No improvement. Patience: 3/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0035
4.706692124695274
7.5880521488694646
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0033
6.442307479622039
10.031352066671706
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0030
4.6444454148742595
7.520939272341323
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0029
4.550013982835041
7.410654131092243
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0035
4.764229671982317
7.712404597849508
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0033
5.274465784394622
8.393381655430177
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0033
5.486780862904648
8.657225109411574
→ No improvement. Patience: 3/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0032
5.413907488453538
8.555991680107716
→ No improvement. Patience: 4/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0030
4.653810509208692
7.554572291482478
→ No improvement. Patience: 5/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0026
5.994859176612746
9.367235740448804
→ No improvement. Patience: 6/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0029
4.306669615605088
7.03994418026119
→ Model improved. Saving...
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0028
4.257549858579007
6.999841734554814
→ Model improved. Saving...
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0028
4.143364577814974
6.835969777402319
→ Model improved. Saving...
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0028
4.148278297686529
6.8646965261397845
→ No improvement. Patience: 1/7
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0031
6.518034043181583
10.02847220755197
→ No improvement. Patience: 2/7
------------------------------
Epoch [41/100], Step [499/499], Loss: 0.0029
5.933172333189714
9.239898719132972
→ No improvement. Patience: 3/7
------------------------------
Epoch [42/100], Step [499/499], Loss: 0.0029
4.297509698392567
7.064736226566169
→ No improvement. Patience: 4/7
------------------------------
Epoch [43/100], Step [499/499], Loss: 0.0028
3.966662701938622
6.68378299499155
→ Model improved. Saving...
------------------------------
Epoch [44/100], Step [499/499], Loss: 0.0027
4.188741843990399
6.934504460954094
→ No improvement. Patience: 1/7
------------------------------
Epoch [45/100], Step [499/499], Loss: 0.0028
4.131976587567094
6.838757336900274
→ No improvement. Patience: 2/7
------------------------------
Epoch [46/100], Step [499/499], Loss: 0.0027
4.616484422459651
7.471333127071051
→ No improvement. Patience: 3/7
------------------------------
Epoch [47/100], Step [499/499], Loss: 0.0026
4.5287208533981165
7.304347809618891
→ No improvement. Patience: 4/7
------------------------------
Epoch [48/100], Step [499/499], Loss: 0.0025
4.457677139429227
7.232900782668869
→ No improvement. Patience: 5/7
------------------------------
Epoch [49/100], Step [499/499], Loss: 0.0026
4.405019728296393
7.190674071726477
→ No improvement. Patience: 6/7
------------------------------
Epoch [50/100], Step [499/499], Loss: 0.0027
4.436549243932591
7.251318155211648
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:49 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:3.966662701938622 test_acc:6.68378299499155
Best model parameters loaded: ./model/14lo.pth
Best model parameters loaded../model/14lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0255
21.291039157186688
31.771815929127733
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0106
9.897464269314758
14.998150592674676
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0099
7.961102885590575
12.164454761511566
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0085
6.703426518541847
10.30949821650637
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0073
6.388770849663672
9.865161086500537
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0064
6.31853702423815
9.777608341987717
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0058
6.719411674654746
10.363014622152352
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0049
6.996156660457944
10.806953117369833
→ No improvement. Patience: 2/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0045
7.555094741483321
11.527999226900326
→ No improvement. Patience: 3/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0036
7.573432230267138
11.508915781877997
→ No improvement. Patience: 4/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0041
5.9635325092763924
9.223858416629087
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0034
7.8250488663034625
11.905667402847586
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0031
6.068581710689293
9.453114136669361
→ No improvement. Patience: 2/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0029
7.021680576791288
10.74769131985874
→ No improvement. Patience: 3/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0025
8.946700234356287
13.410638516446577
→ No improvement. Patience: 4/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0031
4.301368184008457
7.032620710550959
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0029
4.352875970600993
7.0778871071888485
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0027
4.43833017854719
7.215060948888272
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0029
7.586630367778542
11.592530464339234
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0026
5.562166375443087
8.776920525099168
→ No improvement. Patience: 4/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0027
4.5074348296250335
7.3434424997604255
→ No improvement. Patience: 5/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0027
4.1759478331721684
6.816082526106417
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0026
4.191022723284837
6.823641763339852
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0024
4.249902053736092
6.887018966294614
→ No improvement. Patience: 2/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0026
5.403383382120035
8.555785153425505
→ No improvement. Patience: 3/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0025
4.21491041709512
6.9033002764584275
→ No improvement. Patience: 4/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0026
5.336704627237764
8.514865119722653
→ No improvement. Patience: 5/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0025
5.124713630161494
8.158931432993365
→ No improvement. Patience: 6/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0026
4.994826449492323
7.967780174454527
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:28 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:4.1759478331721684 test_acc:6.816082526106417
Best model parameters loaded: ./model/15lo.pth
Best model parameters loaded../model/15lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0337
59.800426589327145
87.72204241667872
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0124
16.434674715885237
24.03883254676891
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0094
13.089554656601512
19.375373590848397
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0078
11.505415139858846
17.211628467572083
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0070
10.791632076908336
16.191051235030578
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0066
9.92165736717372
14.882081890700489
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0063
9.225663937867852
13.849935877078446
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0061
8.689241086258571
13.0955248095581
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0058
8.264333278720924
12.507364252528937
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0056
7.948394411377917
12.067634794096772
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0053
7.724701608125937
11.775640659169348
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0052
7.544114572539721
11.520842607262622
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0050
7.547196747269379
11.553713551130299
→ No improvement. Patience: 1/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0050
7.3646219784569436
11.31365911819278
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0049
7.33721809106751
11.297033069126357
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0048
7.232048697320374
11.159145153654526
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0047
7.0957016324009965
10.967062235825528
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0046
6.972039681431652
10.807403425303287
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0045
6.887735663078068
10.704608495582136
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0044
6.7989857441907535
10.585752863838705
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0043
6.762546764380934
10.533508794237473
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0043
6.54316323757967
10.241888197891948
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0042
6.5299898264023994
10.225930562455243
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0042
6.33331393950868
9.964731789365453
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0041
6.1469356610853625
9.724238691813747
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0041
6.1445649394105315
9.734082209611032
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0039
6.069527105424074
9.640940774319837
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0040
6.155333817016748
9.758488499136405
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0039
5.955974530041422
9.4963310109982
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0039
5.938326638166392
9.46242430718952
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0038
5.90008235359229
9.426979965758521
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0038
5.7917662603228415
9.270712847968664
→ Model improved. Saving...
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0037
5.736311978984161
9.20167548803056
→ Model improved. Saving...
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0037
5.722042303452336
9.189461924801467
→ Model improved. Saving...
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0037
5.636131754039979
9.058331818334215
→ Model improved. Saving...
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0036
5.506944287855181
8.913545886602094
→ Model improved. Saving...
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0036
5.631061736798525
9.082629536745605
→ No improvement. Patience: 1/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0035
5.531577050119539
8.921053065460402
→ No improvement. Patience: 2/7
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0035
5.5392498464217805
8.937077251267302
→ No improvement. Patience: 3/7
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0037
5.513609624270104
8.902493585395856
→ Model improved. Saving...
------------------------------
Epoch [41/100], Step [499/499], Loss: 0.0038
5.815609712372059
9.33094332284376
→ No improvement. Patience: 1/7
------------------------------
Epoch [42/100], Step [499/499], Loss: 0.0038
5.882474094500154
9.435329483838366
→ No improvement. Patience: 2/7
------------------------------
Epoch [43/100], Step [499/499], Loss: 0.0037
5.685545929773599
9.166114201278079
→ No improvement. Patience: 3/7
------------------------------
Epoch [44/100], Step [499/499], Loss: 0.0036
5.669275519890976
9.144442971297458
→ No improvement. Patience: 4/7
------------------------------
Epoch [45/100], Step [499/499], Loss: 0.0035
5.316961638919907
8.677673870718193
→ Model improved. Saving...
------------------------------
Epoch [46/100], Step [499/499], Loss: 0.0034
5.089357716401811
8.370293543349748
→ Model improved. Saving...
------------------------------
Epoch [47/100], Step [499/499], Loss: 0.0033
4.9876613127972
8.253652136563058
→ Model improved. Saving...
------------------------------
Epoch [48/100], Step [499/499], Loss: 0.0033
5.189575732454598
8.518328841724069
→ No improvement. Patience: 1/7
------------------------------
Epoch [49/100], Step [499/499], Loss: 0.0034
5.09966810120088
8.41236432771343
→ No improvement. Patience: 2/7
------------------------------
Epoch [50/100], Step [499/499], Loss: 0.0033
5.2952024717647195
8.66519246497562
→ No improvement. Patience: 3/7
------------------------------
Epoch [51/100], Step [499/499], Loss: 0.0033
5.121773745201531
8.436954540213359
→ No improvement. Patience: 4/7
------------------------------
Epoch [52/100], Step [499/499], Loss: 0.0033
5.279177621886728
8.6343503493436
→ No improvement. Patience: 5/7
------------------------------
Epoch [53/100], Step [499/499], Loss: 0.0033
5.1225308543773895
8.423331899042216
→ No improvement. Patience: 6/7
------------------------------
Epoch [54/100], Step [499/499], Loss: 0.0032
5.148138373300093
8.465391173785997
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:53 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:4.9876613127972 test_acc:8.253652136563058
Best model parameters loaded: ./model/16lo.pth
Best model parameters loaded../model/16lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0355
56.23630100860123
82.9274365961608
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0134
15.50041636754841
22.84365342284004
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0106
12.173568330542253
18.089591850553262
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0091
10.479958617352628
15.695896785925498
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0082
9.391577734562762
14.145279197495272
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0074
8.692516625939746
13.172375011508201
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0067
8.318426598043166
12.679999366627186
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0061
8.265909878344454
12.616379532328361
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0059
8.046272490252875
12.303535879741979
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0057
7.38269939381834
11.39610697234199
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0055
6.996994603030739
10.862379759900918
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0053
6.5002592337009775
10.213251136086841
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0051
6.338496676194044
9.988897282883057
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0049
6.1362681168879325
9.713417808783465
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0048
5.934646207434711
9.44412189513385
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0046
5.731297962900157
9.169673534065918
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
5.679349816719658
9.096165543586459
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0044
5.503118091152633
8.854920612688966
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0043
5.330299999769024
8.614146672972861
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0041
5.231404983788582
8.485109568778455
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0041
5.115037266146245
8.339385508464114
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0040
4.976179361629125
8.173065761586805
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0039
4.857320203923119
8.012643342180551
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0039
4.779662073658706
7.90053102180257
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0039
4.650819368841027
7.732488654263465
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0038
4.615164901896267
7.693167690873941
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0036
4.710280463254218
7.806972808254454
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0037
5.1287062187296675
8.303988245684595
→ No improvement. Patience: 2/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0037
4.626577443488347
7.62356901606145
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0038
4.570314629170611
7.548235699461739
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0037
4.529356400788564
7.496499237647462
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0036
4.430826426225423
7.384965298384025
→ Model improved. Saving...
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0035
4.145721149191591
7.023822608103091
→ Model improved. Saving...
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0035
4.137626267090459
7.0085471692681
→ Model improved. Saving...
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0034
4.107037415850859
6.983280674027775
→ Model improved. Saving...
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0034
4.125062934895914
7.0129862981073146
→ No improvement. Patience: 1/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0035
4.03170989464595
6.896334906521335
→ Model improved. Saving...
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0034
4.361754334774022
7.308700248381187
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0034
4.574170513201894
7.575597555635539
→ No improvement. Patience: 2/7
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0033
4.87267514978381
7.94920174645826
→ No improvement. Patience: 3/7
------------------------------
Epoch [41/100], Step [499/499], Loss: 0.0033
4.956572911318665
8.073394861584076
→ No improvement. Patience: 4/7
------------------------------
Epoch [42/100], Step [499/499], Loss: 0.0034
4.598022208620788
7.576675497499789
→ No improvement. Patience: 5/7
------------------------------
Epoch [43/100], Step [499/499], Loss: 0.0036
3.9044019140134907
6.691840922055088
→ Model improved. Saving...
------------------------------
Epoch [44/100], Step [499/499], Loss: 0.0033
5.494183251202548
8.780519831781152
→ No improvement. Patience: 1/7
------------------------------
Epoch [45/100], Step [499/499], Loss: 0.0032
4.1453416787031045
6.9995271363964315
→ No improvement. Patience: 2/7
------------------------------
Epoch [46/100], Step [499/499], Loss: 0.0032
3.8628180111999892
6.638320393286745
→ Model improved. Saving...
------------------------------
Epoch [47/100], Step [499/499], Loss: 0.0033
3.8583878181901206
6.622447357174002
→ Model improved. Saving...
------------------------------
Epoch [48/100], Step [499/499], Loss: 0.0033
4.406765894177768
7.315887932075295
→ No improvement. Patience: 1/7
------------------------------
Epoch [49/100], Step [499/499], Loss: 0.0032
4.414039131545129
7.3216502839612705
→ No improvement. Patience: 2/7
------------------------------
Epoch [50/100], Step [499/499], Loss: 0.0032
4.3109384706318785
7.1944493480278915
→ No improvement. Patience: 3/7
------------------------------
Epoch [51/100], Step [499/499], Loss: 0.0032
4.13993386622938
6.963370670798322
→ No improvement. Patience: 4/7
------------------------------
Epoch [52/100], Step [499/499], Loss: 0.0031
4.0419383374434
6.842378174872877
→ No improvement. Patience: 5/7
------------------------------
Epoch [53/100], Step [499/499], Loss: 0.0030
3.6479993968072275
6.356027646405576
→ Model improved. Saving...
------------------------------
Epoch [54/100], Step [499/499], Loss: 0.0031
3.624834367212111
6.3175856760384
→ Model improved. Saving...
------------------------------
Epoch [55/100], Step [499/499], Loss: 0.0031
3.834942637749512
6.611007486167893
→ No improvement. Patience: 1/7
------------------------------
Epoch [56/100], Step [499/499], Loss: 0.0030
4.583903664680442
7.568818607602329
→ No improvement. Patience: 2/7
------------------------------
Epoch [57/100], Step [499/499], Loss: 0.0030
4.508769777160953
7.45597233184515
→ No improvement. Patience: 3/7
------------------------------
Epoch [58/100], Step [499/499], Loss: 0.0030
4.763847531977884
7.793294492163075
→ No improvement. Patience: 4/7
------------------------------
Epoch [59/100], Step [499/499], Loss: 0.0030
4.63025618375715
7.62206451636262
→ No improvement. Patience: 5/7
------------------------------
Epoch [60/100], Step [499/499], Loss: 0.0030
4.655900389095014
7.650248829133394
→ No improvement. Patience: 6/7
------------------------------
Epoch [61/100], Step [499/499], Loss: 0.0031
4.132857300640943
6.973250198788903
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:60 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:3.624834367212111 test_acc:6.3175856760384
Best model parameters loaded: ./model/17lo.pth
Best model parameters loaded../model/17lo.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0225
31.39163687792842
46.63506132403854
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0106
13.406601819462125
20.074860248076774
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0087
10.625678801201204
16.08745455546186
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0077
9.243962413500611
14.04239472980787
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0071
8.456630036441446
12.754154229036672
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0065
7.848815199565452
11.849766112156336
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0061
7.081795053717694
10.802835053482836
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0058
6.589993614085513
10.137973478678024
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0055
6.146414607042704
9.540396845767527
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0054
5.879810901867901
9.17436430827069
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0051
5.73563843478013
8.989623179557766
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0049
5.656161209042912
8.877000258839852
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0048
5.462670998203183
8.61282056627564
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0048
5.276822402398154
8.378610811658586
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0046
5.159796956169883
8.222090347143865
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0044
4.857670738935331
7.839490001511174
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
4.894420933423397
7.891069254875012
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0043
4.755938585702863
7.7192154341564825
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0043
4.678864805063841
7.62092165424283
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
4.520563400410596
7.416638189860347
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0042
4.434013853234202
7.293896555180672
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0042
4.41495463737515
7.299452140095662
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0043
5.695771345789469
9.033816318898648
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0039
5.67784866242238
9.01124428531679
→ No improvement. Patience: 3/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0037
5.043155925243879
8.17949655356481
→ No improvement. Patience: 4/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0036
5.341991361180891
8.557353555876713
→ No improvement. Patience: 5/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0036
5.521123064465633
8.77421986802422
→ No improvement. Patience: 6/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0036
5.096943054210776
8.204848622792934
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:27 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:4.434013853234202 test_acc:7.293896555180672
Best model parameters loaded: ./model/18lo.pth
Best model parameters loaded../model/18lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0374
52.09937702547407
76.49199645765324
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0098
13.626675204999508
19.972297841748944
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0082
11.960271297030145
17.617531232068533
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0074
10.678640536068936
15.823061030261364
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0070
9.90794921281648
14.745863608188966
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0075
9.822287133527663
14.590483227715213
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0074
9.062741360968095
13.529680853407019
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0072
9.133239125158255
13.59974341260801
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0071
8.82019060877906
13.148834945650302
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0065
9.592167285115462
14.228377769120293
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0063
9.0520418814621
13.479460861225952
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0060
8.157368557596914
12.221580607697442
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0059
7.857842913662023
11.903298655548852
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0056
8.134360218481177
12.361696093637322
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0055
8.195293945336868
12.48241944651053
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0053
8.326821401707045
12.698925385347732
→ No improvement. Patience: 3/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0051
7.60958137063017
11.681518052237655
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0053
8.662209421404226
13.166600945520921
→ No improvement. Patience: 1/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0049
8.86088966606901
13.495561606999152
→ No improvement. Patience: 2/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0049
8.562479209866643
13.090240411306569
→ No improvement. Patience: 3/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0047
8.456852827514691
12.94091771882129
→ No improvement. Patience: 4/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0047
8.812060879766452
13.461917203795242
→ No improvement. Patience: 5/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0047
9.441047023264407
14.329791462569398
→ No improvement. Patience: 6/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0045
8.70116319264444
13.311471280145303
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:23 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:7.60958137063017 test_acc:11.681518052237655
Best model parameters loaded: ./model/19lo.pth
Best model parameters loaded../model/19lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0176
20.5588053471562
30.589097673051135
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0071
8.845394849441584
13.49184539293112
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0053
7.532481500416641
11.618474080046006
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0046
6.38942644389303
9.905535617617016
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0041
6.2101410244799675
9.728374375891221
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0039
6.225764493648097
9.706580099548662
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0035
5.468998649021531
8.68938325783944
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0034
5.71633139819996
9.00567692717669
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0031
5.8273285859984085
9.155737211479279
→ No improvement. Patience: 2/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0030
7.139895502717642
10.959658240967684
→ No improvement. Patience: 3/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0037
6.0718332630992915
9.445315592256316
→ No improvement. Patience: 4/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0032
6.186861071457149
9.649328867585531
→ No improvement. Patience: 5/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0030
5.423684080865981
8.594305024731394
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0028
6.007928208445628
9.358308936108946
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0026
4.919503151267691
7.896443347368408
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0028
4.945726148446976
8.006262914250318
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0028
4.8965912453511775
7.920722658104601
→ No improvement. Patience: 2/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0027
5.060512989236457
8.104214373971061
→ No improvement. Patience: 3/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0028
4.438607561278028
7.227261238498365
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0028
4.255552593677812
7.097832826935607
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0031
4.2490912684426565
7.071714587439409
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0030
4.782865023213879
7.777200085590995
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0028
4.6444178095680435
7.609915255318578
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0029
5.348097859860797
8.463726303299401
→ No improvement. Patience: 3/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0032
6.239855959235774
9.589661750178248
→ No improvement. Patience: 4/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0030
5.871323878559942
9.243070127146762
→ No improvement. Patience: 5/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0027
4.622318876665049
7.47789811101233
→ No improvement. Patience: 6/7
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0025
4.61301982295296
7.405263614393289
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:27 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:4.2490912684426565 test_acc:7.071714587439409
Best model parameters loaded: ./model/20lo.pth
Best model parameters loaded../model/20lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0210
17.727221824099455
26.43339411328837
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0088
9.703062883751782
14.71191615179131
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0073
7.200915655125966
11.055247925928068
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0062
6.4743983532711145
9.98452736877899
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0057
6.078625857002079
9.403947900458414
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0059
5.93287947690576
9.283355236832918
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0055
5.747362561837713
8.982054587716393
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0060
7.066083829761232
10.949844526103957
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0041
5.289441741225913
8.407183650665553
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0047
5.941014542969369
9.312566330960468
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0046
5.916203615342599
9.249333897139794
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0046
5.3205106611696396
8.567954826340095
→ No improvement. Patience: 3/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0043
10.004740035275795
15.010820817148552
→ No improvement. Patience: 4/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0041
10.275380070915341
15.469754370137567
→ No improvement. Patience: 5/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0049
8.169170801940455
12.431480846621373
→ No improvement. Patience: 6/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0038
8.038251006837001
12.178909989158969
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:15 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:5.289441741225913 test_acc:8.407183650665553
Best model parameters loaded: ./model/21lo.pth
Best model parameters loaded../model/21lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0279
76.49715506434808
112.49712874718419
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0082
11.995084985315302
17.90493337433476
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0063
9.740543370424431
14.574615819930019
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0056
9.013920311240438
13.481716156874402
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0056
8.566692743592354
12.820291269131019
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0055
8.845331031369515
13.2254864832745
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0053
8.331323655837766
12.519192950849298
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0053
7.799738285877564
11.772388479288633
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0053
7.814086139328274
11.821550679721312
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0050
7.399500757457987
11.263470634930847
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0050
7.0574588596740195
10.827970605307838
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0049
7.058778105921374
10.841118907816705
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0047
6.696585240996564
10.37799298101004
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0046
6.938728964581118
10.7291758262427
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0045
6.567018385903183
10.218623998360883
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0045
6.621361919476157
10.308674169071821
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
6.856948542979981
10.631705190853282
→ No improvement. Patience: 2/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0045
7.336687953856832
11.30332286025724
→ No improvement. Patience: 3/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0044
6.471420863951394
10.117334326307645
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
6.446399271038542
10.088017011399433
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0042
6.401080341619021
10.068769122939672
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0041
6.293189946781051
9.912349432968275
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0040
6.387713846964827
10.063116222085405
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0040
6.370067683365469
10.018729482062906
→ No improvement. Patience: 2/7
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0040
6.027273314165474
9.59565795551194
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0037
5.926131832991952
9.446122426473895
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0038
5.79753942081268
9.2905647140812
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0037
5.898353815132077
9.435385096026303
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0037
5.90135091990118
9.460812623426825
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0038
5.7857577003910095
9.299863130529058
→ No improvement. Patience: 3/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0037
5.746636160120562
9.253597016157286
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0037
5.714558725022619
9.189026517825887
→ Model improved. Saving...
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0035
5.596683043375253
9.06119172136414
→ Model improved. Saving...
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0035
5.706829486344078
9.191424829897443
→ No improvement. Patience: 1/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0036
5.710617658412309
9.18151756793654
→ No improvement. Patience: 2/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0035
5.5275028318434405
8.922588450733924
→ Model improved. Saving...
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0036
5.452716738229982
8.817535779082029
→ Model improved. Saving...
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0035
5.447833391760465
8.825669677718942
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0036
5.530606121177706
8.976326581582086
→ No improvement. Patience: 2/7
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0037
6.296647915992179
9.995263245465576
→ No improvement. Patience: 3/7
------------------------------
Epoch [41/100], Step [499/499], Loss: 0.0034
6.764566270434861
10.64804693665307
→ No improvement. Patience: 4/7
------------------------------
Epoch [42/100], Step [499/499], Loss: 0.0035
6.6440827204517126
10.476758602692216
→ No improvement. Patience: 5/7
------------------------------
Epoch [43/100], Step [499/499], Loss: 0.0035
6.275582146475834
9.99435614726049
→ No improvement. Patience: 6/7
------------------------------
Epoch [44/100], Step [499/499], Loss: 0.0035
6.12219525101366
9.769966708370514
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:43 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:5.452716738229982 test_acc:8.817535779082029
Best model parameters loaded: ./model/22lo.pth
Best model parameters loaded../model/22lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0282
21.147256511667592
31.460653969555878
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0080
8.610383521371675
13.082393163493846
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0060
6.814908192901648
10.499286570993792
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0047
5.883180238905857
9.226079883465962
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0041
5.8867907251627765
9.230972075278622
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0038
6.032490143686082
9.445591158707922
→ No improvement. Patience: 2/7
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0035
6.25786121889092
9.723130724862191
→ No improvement. Patience: 3/7
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0034
5.979855782602423
9.342150817757185
→ No improvement. Patience: 4/7
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0037
5.359091762596173
8.511927092304868
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0031
5.21602125581521
8.46285829444448
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0031
5.117364055392911
8.29594198176394
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0030
4.826930692477831
7.898063586226005
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0029
4.520880565020462
7.489186892465882
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0028
4.564051119489737
7.516669373516169
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0027
4.950719033372895
7.983978618852614
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0027
5.239343060625404
8.38929340770789
→ No improvement. Patience: 3/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0028
5.747168793332848
9.031408616411774
→ No improvement. Patience: 4/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0031
6.906411331230689
10.73828295237122
→ No improvement. Patience: 5/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0030
4.308703694718584
7.129647340660469
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0028
4.833978798194556
7.804285018333876
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0028
4.394633752932051
7.228345973401464
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0029
4.50231353180722
7.457374786162592
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0026
4.507927749637046
7.4434016963388245
→ No improvement. Patience: 4/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0025
4.213381647180744
7.059864200396278
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0025
3.961330195675834
6.66921549578752
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0024
3.8822306825447215
6.532643355427975
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0023
3.845807822973318
6.476256593773648
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0023
3.9407453849277143
6.567170505137132
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0023
4.0077143635387324
6.637811017152009
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0023
4.774128613536959
7.640369988792507
→ No improvement. Patience: 3/7
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0025
4.28484852627907
6.987733914674696
→ No improvement. Patience: 4/7
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0024
4.195261314079169
6.940961930700442
→ No improvement. Patience: 5/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0024
5.042048356052194
8.125514310038975
→ No improvement. Patience: 6/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0025
5.585166617546261
8.876866256438232
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:33 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:3.845807822973318 test_acc:6.476256593773648
Best model parameters loaded: ./model/23lo.pth
Best model parameters loaded../model/23lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0236
23.58570920879165
35.13740660972182
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0103
13.458157188295852
20.226456467161945
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0081
8.765636092036798
13.262791560805974
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0072
7.069019232865446
10.876164421219793
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0073
6.490344982022565
10.09554662010994
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0065
6.312512566851742
9.843575388547395
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0058
5.9674276017970955
9.304868846902089
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0056
5.788554871309526
9.073024717587568
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0050
5.863236660533758
9.159435332458898
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0050
5.4433177659064
8.562171227170623
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0047
5.478741324579603
8.647857911248003
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0044
6.542720119154719
10.045027738476191
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0045
7.35602494827391
11.272929326772655
→ No improvement. Patience: 3/7
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0045
6.442141306408906
9.997139537789694
→ No improvement. Patience: 4/7
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0036
8.795604792617524
13.231598125486073
→ No improvement. Patience: 5/7
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0042
5.791563579236493
9.045980051720937
→ No improvement. Patience: 6/7
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0035
6.4920802280425525
10.005148096449485
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:16 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:5.4433177659064 test_acc:8.562171227170623
Best model parameters loaded: ./model/24lo.pth
Best model parameters loaded../model/24lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/100], Step [499/499], Loss: 0.0355
86.49002001224838
127.05219350806895
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0132
17.422940764641186
25.44464988093243
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0104
15.49156635327813
22.691718613936583
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0084
12.575525857246383
18.59801537870461
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0068
10.978767001913175
16.325384616643348
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0060
10.105144941937025
15.090055942530427
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0057
9.575089780059232
14.311913948452
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0056
9.022160539861234
13.483180515855546
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0056
8.621640050220124
12.931183438437413
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0054
8.365579314643556
12.60139482676339
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0053
8.203609390042129
12.408521571022872
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0052
8.028975302104692
12.194686325575539
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0049
7.785343974288945
11.874079053028655
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0049
7.593858928120128
11.611336732052152
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0047
7.3476682162797715
11.283727749070342
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0046
7.238114904359203
11.130194498703268
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0044
7.061689386751762
10.876605562857891
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0043
7.026110255169364
10.84870367374402
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0042
6.9720330151386145
10.788729267683118
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
6.8709158466864295
10.650672075818822
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0040
6.8421048842893235
10.626588854689247
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0040
6.681497832243154
10.417293672635786
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0040
6.70112270042257
10.456623798804708
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0038
6.5502519819658875
10.26056401126791
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0038
6.590069376812913
10.317987960647722
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0038
6.510553843786802
10.203996746058518
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0038
6.423022445030707
10.111159449678683
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0037
6.454026278324029
10.14836026793012
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0036
6.09665187894369
9.67765351350454
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0036
5.968218167293145
9.5077362781527
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0036
5.602409091852491
8.999448914562539
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0035
5.874948202923861
9.387929333842179
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0035
5.752742015833861
9.23709238751335
→ No improvement. Patience: 2/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0035
5.626814304920657
9.08340881952259
→ No improvement. Patience: 3/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0035
5.590433857447781
9.032285320248596
→ No improvement. Patience: 4/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0035
5.802441189808087
9.324456476012578
→ No improvement. Patience: 5/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0034
5.57831472629369
9.027735667550013
→ No improvement. Patience: 6/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0035
5.5839227129647995
9.038042534030367
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:37 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:5.602409091852491 test_acc:8.999448914562539
Best model parameters loaded: ./model/25lo.pth
Best model parameters loaded../model/25lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/100], Step [499/499], Loss: 0.0541
71.23605526900664
104.97265339792884
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0147
17.262695165889145
25.313405440167674
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0114
13.365270802796553
19.603895303510132
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0092
11.281181029836763
16.72577998906864
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0080
9.906074597261354
14.771721895193108
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0074
9.098484296818194
13.567169518785608
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0072
8.401782059464002
12.566941075943893
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0069
7.7028528953102136
11.627339621386676
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0064
7.41283234476853
11.284080316904399
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0060
7.254654383406625
11.049766023528164
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0057
7.0014565962844495
10.683652686915659
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0055
6.7729463515891215
10.34204736211078
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0053
6.357475839192037
9.76859648744702
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0050
6.211213274327321
9.577125891500016
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0049
5.958949351481281
9.23582830214296
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0047
5.863782393059213
9.106884188319642
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0046
5.923917154437212
9.199773369889966
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0044
6.100405035702791
9.458522671788613
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0043
5.915561374111452
9.226329914168607
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0042
5.761604773834243
9.028650649120467
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0043
5.137740004506087
8.151934943206964
→ Model improved. Saving...
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0041
4.901410045754448
7.827999470468154
→ Model improved. Saving...
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0041
4.804932615065016
7.712995200290257
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0039
4.757916210044672
7.655356453764984
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0039
4.729180197241164
7.629388906516757
→ Model improved. Saving...
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0038
4.675333377710044
7.555135676337845
→ Model improved. Saving...
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0038
4.4444552038790786
7.248984315063207
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0037
4.368352427556482
7.157732023891259
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0036
4.368683614765343
7.174611012200138
→ No improvement. Patience: 1/7
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0036
4.3160674668026475
7.106717531144786
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0035
4.232956316530694
7.010712304901203
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0035
4.373549677302333
7.207643264601733
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0034
4.587365968942836
7.514579153393241
→ No improvement. Patience: 2/7
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0033
4.71552882886284
7.683338079015054
→ No improvement. Patience: 3/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0035
4.6064279541566995
7.5162288443276095
→ No improvement. Patience: 4/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0034
4.492450466239587
7.4084399560993
→ No improvement. Patience: 5/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0035
5.242336247130633
8.415141637095168
→ No improvement. Patience: 6/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0033
5.951354656736889
9.394930640669225
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:37 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:4.232956316530694 test_acc:7.010712304901203
Best model parameters loaded: ./model/26lo.pth
Best model parameters loaded../model/26lo.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/100], Step [499/499], Loss: 0.0437
48.51210146538374
71.50641319709001
→ Model improved. Saving...
------------------------------
Epoch [2/100], Step [499/499], Loss: 0.0126
16.061375367412207
23.909849889588536
→ Model improved. Saving...
------------------------------
Epoch [3/100], Step [499/499], Loss: 0.0094
12.022260835259086
17.93460459501923
→ Model improved. Saving...
------------------------------
Epoch [4/100], Step [499/499], Loss: 0.0082
10.364480250631594
15.55377327703903
→ Model improved. Saving...
------------------------------
Epoch [5/100], Step [499/499], Loss: 0.0077
9.277004378865792
13.978691461914158
→ Model improved. Saving...
------------------------------
Epoch [6/100], Step [499/499], Loss: 0.0071
8.743240830363076
13.20659299810072
→ Model improved. Saving...
------------------------------
Epoch [7/100], Step [499/499], Loss: 0.0069
7.962293028765061
12.056969249853678
→ Model improved. Saving...
------------------------------
Epoch [8/100], Step [499/499], Loss: 0.0065
7.403777535664678
11.274698013949235
→ Model improved. Saving...
------------------------------
Epoch [9/100], Step [499/499], Loss: 0.0060
6.9392753125446704
10.611336230774564
→ Model improved. Saving...
------------------------------
Epoch [10/100], Step [499/499], Loss: 0.0056
6.556603490189617
10.081338650730427
→ Model improved. Saving...
------------------------------
Epoch [11/100], Step [499/499], Loss: 0.0052
6.5051102357217845
10.021932389326937
→ Model improved. Saving...
------------------------------
Epoch [12/100], Step [499/499], Loss: 0.0048
6.314414233631069
9.73796198252624
→ Model improved. Saving...
------------------------------
Epoch [13/100], Step [499/499], Loss: 0.0046
6.2769447368235936
9.681916653189898
→ Model improved. Saving...
------------------------------
Epoch [14/100], Step [499/499], Loss: 0.0044
5.867847800427545
9.10438963341981
→ Model improved. Saving...
------------------------------
Epoch [15/100], Step [499/499], Loss: 0.0042
5.553969778367924
8.685255124122211
→ Model improved. Saving...
------------------------------
Epoch [16/100], Step [499/499], Loss: 0.0040
5.039834387682025
7.992119871510586
→ Model improved. Saving...
------------------------------
Epoch [17/100], Step [499/499], Loss: 0.0039
4.706704494407671
7.529056786743692
→ Model improved. Saving...
------------------------------
Epoch [18/100], Step [499/499], Loss: 0.0037
4.681544678128351
7.522444941100132
→ Model improved. Saving...
------------------------------
Epoch [19/100], Step [499/499], Loss: 0.0036
4.567508415968724
7.3656911657073625
→ Model improved. Saving...
------------------------------
Epoch [20/100], Step [499/499], Loss: 0.0035
4.520925530550813
7.32361952622281
→ Model improved. Saving...
------------------------------
Epoch [21/100], Step [499/499], Loss: 0.0034
4.927707708794577
7.88527830936406
→ No improvement. Patience: 1/7
------------------------------
Epoch [22/100], Step [499/499], Loss: 0.0032
4.7105906363316805
7.6107066137172055
→ No improvement. Patience: 2/7
------------------------------
Epoch [23/100], Step [499/499], Loss: 0.0031
4.2419320275942125
7.008067600415586
→ Model improved. Saving...
------------------------------
Epoch [24/100], Step [499/499], Loss: 0.0030
3.8139659937261756
6.4774717114798985
→ Model improved. Saving...
------------------------------
Epoch [25/100], Step [499/499], Loss: 0.0030
3.857920340735591
6.5197778349736115
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/100], Step [499/499], Loss: 0.0030
4.153035286974757
6.895641431613562
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/100], Step [499/499], Loss: 0.0029
3.823065735468392
6.443155658103487
→ Model improved. Saving...
------------------------------
Epoch [28/100], Step [499/499], Loss: 0.0028
3.7246434927294594
6.312173663995048
→ Model improved. Saving...
------------------------------
Epoch [29/100], Step [499/499], Loss: 0.0028
3.7208472886990904
6.299743136649614
→ Model improved. Saving...
------------------------------
Epoch [30/100], Step [499/499], Loss: 0.0027
3.51556022703477
6.055527382662756
→ Model improved. Saving...
------------------------------
Epoch [31/100], Step [499/499], Loss: 0.0026
3.36322503998458
5.866342274460087
→ Model improved. Saving...
------------------------------
Epoch [32/100], Step [499/499], Loss: 0.0027
3.326834998758513
5.8126963591742875
→ Model improved. Saving...
------------------------------
Epoch [33/100], Step [499/499], Loss: 0.0026
3.322110657955628
5.7927022825359575
→ Model improved. Saving...
------------------------------
Epoch [34/100], Step [499/499], Loss: 0.0027
3.752697278771895
6.335258237806953
→ No improvement. Patience: 1/7
------------------------------
Epoch [35/100], Step [499/499], Loss: 0.0025
3.7159471406561866
6.295635951173395
→ No improvement. Patience: 2/7
------------------------------
Epoch [36/100], Step [499/499], Loss: 0.0025
4.171578413603038
6.884852041865583
→ No improvement. Patience: 3/7
------------------------------
Epoch [37/100], Step [499/499], Loss: 0.0027
3.851483742984394
6.462685615523556
→ No improvement. Patience: 4/7
------------------------------
Epoch [38/100], Step [499/499], Loss: 0.0029
4.8608291795437095
7.755964484369639
→ No improvement. Patience: 5/7
------------------------------
Epoch [39/100], Step [499/499], Loss: 0.0026
3.562854920322928
6.0806786009092795
→ No improvement. Patience: 6/7
------------------------------
Epoch [40/100], Step [499/499], Loss: 0.0025
3.6287559125648468
6.167930955436759
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:39 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:3.322110657955628 test_acc:5.7927022825359575
Best model parameters loaded: ./model/27lo.pth
Best model parameters loaded../model/27lo.pth


















(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0054
22.23287316802729
32.39402612145027
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0033
12.626492715431786
18.580823064821814
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0022
13.22227103225763
19.43435528973019
→ No improvement. Patience: 1/7
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0016
12.095366290929705
17.898163806539046
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0017
10.590207343271338
15.774673475943532
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0016
10.29125249204048
15.334214008623302
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0016
9.567574108263228
14.312763336903947
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0015
9.256256976116441
13.904361536404075
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0016
8.607892426821937
12.988485993914846
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0016
8.398390459500238
12.679678133000936
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0017
8.185678359593533
12.445504434839945
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0017
8.281714340752945
12.632679182161112
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0016
8.126139320598213
12.397322593488626
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0017
7.912856893586519
12.133816521242885
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0017
7.8590398067974885
12.07870382419512
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0017
7.77822364698518
11.964301227044261
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0018
7.882811132440548
12.161436074969206
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0017
7.888546862578701
12.185405396705953
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0017
7.739819000927471
11.998776156643672
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0018
7.382124618267641
11.545945540509887
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0018
7.332154839391791
11.467391565161954
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0017
7.3279833804586
11.48999559480983
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0017
7.136760026401259
11.221287290677884
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0018
7.200535876220457
11.311095573487334
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0017
7.100272467814395
11.17199538472887
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0018
7.194718238036836
11.332098579700608
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0017
7.200139658959935
11.317056145206605
→ No improvement. Patience: 2/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0017
7.156231823037762
11.24460980960118
→ No improvement. Patience: 3/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0017
7.052523165854585
11.116800153064208
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0016
6.952353476120677
10.983041294066643
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0016
6.9477022813632265
10.966701932001895
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0017
7.008583105061854
11.063794147995564
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0015
7.090939253046829
11.162481196448551
→ No improvement. Patience: 2/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0014
7.061947957616924
11.135743201107239
→ No improvement. Patience: 3/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0014
6.977214071075917
11.01144907577559
→ No improvement. Patience: 4/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0014
6.914388039753934
10.943304801607272
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0014
6.814925888049164
10.80904647253502
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0014
6.95420194584321
10.986500269416204
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0013
6.702868335777569
10.631268040049147
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0014
6.675422838001796
10.620516023117835
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0014
6.69509623405641
10.617183693928197
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0013
6.657469169641756
10.563972638237008
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0014
6.667693143288992
10.578848570369376
→ No improvement. Patience: 1/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0014
6.584140360358443
10.469728533913152
→ Model improved. Saving...
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0013
6.637744689332028
10.533935711441206
→ No improvement. Patience: 1/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0013
6.630260895765483
10.519220133719573
→ No improvement. Patience: 2/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0013
6.514962991446155
10.356178751075843
→ Model improved. Saving...
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0013
6.606088068286674
10.488143127521257
→ No improvement. Patience: 1/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0013
6.664627523064482
10.545301199421495
→ No improvement. Patience: 2/7
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0013
6.459570844667529
10.299171031669847
→ Model improved. Saving...
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0013
6.606905032956193
10.489262443283364
→ No improvement. Patience: 1/7
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0013
6.467422145305688
10.310456959266174
→ No improvement. Patience: 2/7
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0013
6.313057973018721
10.129483883340834
→ Model improved. Saving...
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0013
6.41421131461536
10.272401186822947
→ No improvement. Patience: 1/7
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0013
6.462303069586459
10.279418832570146
→ No improvement. Patience: 2/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0012
6.33692633555633
10.139998176389287
→ No improvement. Patience: 3/7
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0012
6.446407152557939
10.27235487631835
→ No improvement. Patience: 4/7
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0012
6.315219300567285
10.080854801277127
→ Model improved. Saving...
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0012
6.3492140354548745
10.12289512216755
→ No improvement. Patience: 1/7
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0012
6.522947226828116
10.33562667678818
→ No improvement. Patience: 2/7
------------------------------
Epoch [61/300], Step [499/499], Loss: 0.0012
6.467561911162915
10.257956356083488
→ No improvement. Patience: 3/7
------------------------------
Epoch [62/300], Step [499/499], Loss: 0.0011
6.440927053272421
10.225306821720912
→ No improvement. Patience: 4/7
------------------------------
Epoch [63/300], Step [499/499], Loss: 0.0011
6.698962452298475
10.587992195133456
→ No improvement. Patience: 5/7
------------------------------
Epoch [64/300], Step [499/499], Loss: 0.0012
6.6007581921924965
10.426595707456142
→ No improvement. Patience: 6/7
------------------------------
Epoch [65/300], Step [499/499], Loss: 0.0012
6.446941755893748
10.259195764515272
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:64 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:6.315219300567285 test_acc:10.080854801277127
Best model parameters loaded: ./model/1la.pth
Best model parameters loaded../model/1la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0042
12.485343342264665
18.421572444800088
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0014
8.922517036811842
13.55420127293353
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0012
8.864581957583212
13.565873601547326
→ No improvement. Patience: 1/7
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0010
7.213157185096443
11.222458334406488
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0010
6.933266678626576
10.83821148071741
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0010
6.311549091345669
9.979791982745688
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0011
6.30593836974972
9.946046355046835
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0013
6.380382180105932
10.023033633003914
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0010
6.7165351376640965
10.500613158083508
→ No improvement. Patience: 2/7
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0009
6.248059172352378
9.921749396177452
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0009
5.967440585754058
9.556243351389421
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.65172335761254
9.107501400082999
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
5.769918522263531
9.192034493521158
→ No improvement. Patience: 1/7
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0011
5.6877734718333715
9.11232909809024
→ No improvement. Patience: 2/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0011
5.478620408588895
8.796239014696512
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0014
6.296024127788431
9.855671425209648
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0012
5.326929923884366
8.658622314108419
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0012
5.1651473170366895
8.450937743446865
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.755335193689679
9.247042123396483
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0012
5.468052231863608
8.800039026262304
→ No improvement. Patience: 2/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
6.01646208692188
9.667158726999084
→ No improvement. Patience: 3/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
5.584837047688317
8.887835790510907
→ No improvement. Patience: 4/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
5.109148851319625
8.243312597487401
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0009
5.166476620996075
8.446269341728458
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0010
5.191365571545964
8.523045064426205
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0010
4.940015531463097
8.157857442986709
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
5.2162343191550855
8.5966439721499
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
5.125939628730889
8.40536412487779
→ No improvement. Patience: 2/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
5.4042494651874655
8.85832556849241
→ No improvement. Patience: 3/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0011
5.445289337375827
8.781251395930749
→ No improvement. Patience: 4/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0012
5.710262579084248
9.11701933490679
→ No improvement. Patience: 5/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0011
5.337626203588028
8.607377860740574
→ No improvement. Patience: 6/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
5.791345025736756
9.228859545031549
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:32 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:4.940015531463097 test_acc:8.157857442986709
Best model parameters loaded: ./model/2la.pth
Best model parameters loaded../model/2la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0056
16.81973016221726
24.73643820934103
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0031
11.013453117912926
16.55716059720926
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0023
10.156354257725205
15.231707278233513
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0021
8.074619406840025
12.314124205329563
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0019
6.712195170840627
10.463251479451301
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0018
9.09629143843555
13.760633577862924
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0019
6.459966625682853
10.062607390278309
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0016
6.75788113692391
10.556972159860367
→ No improvement. Patience: 1/7
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0017
6.888535729419247
10.66884208742507
→ No improvement. Patience: 2/7
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0013
5.7099295796131555
9.112513893117857
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0013
5.7644100995095116
9.103645690558098
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.5856818083775375
8.878598051283184
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
5.5849787664451025
8.835290225938289
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0012
6.189427555102263
9.684353844486168
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
5.350476272832616
8.608558151747493
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0014
5.895520116435021
9.290719117250312
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0012
5.591692964664655
8.894003364678648
→ No improvement. Patience: 2/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0013
5.906500387369231
9.285426144751101
→ No improvement. Patience: 3/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0015
6.401056000719855
10.023981230185496
→ No improvement. Patience: 4/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0011
6.016735029686281
9.468326626227483
→ No improvement. Patience: 5/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0012
5.1992306129344685
8.369580551108163
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0016
5.8014372205772515
9.18894833116834
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0015
5.948925099908786
9.297845777308734
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0010
6.808478803080103
10.508529547258659
→ No improvement. Patience: 3/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0010
5.188161964748108
8.272938868440145
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
5.537979031989651
8.882773317131644
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
5.098238354330309
8.244455838314167
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0009
4.6023904260578385
7.560477981040175
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
4.654710232581526
7.683397537488984
→ No improvement. Patience: 1/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.444940899180087
7.35791381935424
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0010
5.183518693814183
8.360474496147589
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0009
4.9826322268214245
8.03198685475041
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
4.7606009945204555
7.902025190286567
→ No improvement. Patience: 3/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0009
4.637727948698943
7.660576322403718
→ No improvement. Patience: 4/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
5.271097699224886
8.419368380721096
→ No improvement. Patience: 5/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0009
4.43207852082771
7.383570193738944
→ No improvement. Patience: 6/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.408799331986844
7.338107876989621
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0012
4.826284236531059
7.978749910880539
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0010
4.679085677765219
7.82176331332955
→ No improvement. Patience: 2/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0008
4.747081824881136
7.7984213052927345
→ No improvement. Patience: 3/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0008
4.349704105875274
7.3204091956360955
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0008
4.374407124285016
7.414794506768874
→ No improvement. Patience: 1/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0008
4.990562455199619
8.213074943046536
→ No improvement. Patience: 2/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0008
4.619447901107517
7.681772135429625
→ No improvement. Patience: 3/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0008
4.644637534073296
7.678827256404343
→ No improvement. Patience: 4/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0008
5.587183191490778
8.921338934999069
→ No improvement. Patience: 5/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0010
4.618575823265106
7.595873315957894
→ No improvement. Patience: 6/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0015
4.512165635375958
7.545944121224856
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:47 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:4.349704105875274 test_acc:7.3204091956360955
Best model parameters loaded: ./model/3la.pth
Best model parameters loaded../model/3la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0061
21.763058775051885
31.90187100920997
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0020
12.054947757769108
17.853493011125813
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0015
9.978247994996714
14.965150925402824
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0015
8.59282842182309
13.043676917683701
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0015
7.935026150046022
12.136167352732084
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0013
7.576583867288353
11.63979367741742
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0012
7.301121959729759
11.257859796179261
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0012
7.082761583771396
10.944422171280046
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
6.82300488985884
10.55785909712412
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0011
6.688504686571897
10.366693800150342
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0012
6.534531817262637
10.12721561626175
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
6.440699861509858
10.005283013188318
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0011
6.3265305645858465
9.852686264087694
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0011
6.211994447641766
9.689163356046762
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0011
6.101247878259027
9.580823296887232
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0011
6.092334032675656
9.583304139412052
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0010
6.113998167236223
9.630424248630524
→ No improvement. Patience: 2/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0011
6.1502540952041755
9.712731875168407
→ No improvement. Patience: 3/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0011
6.295717047166336
9.923843678818502
→ No improvement. Patience: 4/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0011
6.233894690133486
9.8397960968696
→ No improvement. Patience: 5/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0010
6.19422434162751
9.791826154787511
→ No improvement. Patience: 6/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0010
6.203785591303535
9.807332204235685
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:21 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:6.101247878259027 test_acc:9.580823296887232
Best model parameters loaded: ./model/4la.pth
Best model parameters loaded../model/4la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0069
15.402205017393216
22.523196852672655
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0027
10.709280599479532
16.113847062166275
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0015
11.125737968098063
16.72990989131872
→ No improvement. Patience: 1/7
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0014
9.0673891610105
13.82492647936265
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0013
7.557739680675079
11.7180643173157
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0015
7.053479415103405
11.042206700801152
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0014
6.765153681897387
10.670114761002944
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0014
6.511240928689709
10.302230889016517
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
6.236657278777009
9.921809885108138
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
6.19787139157668
9.879365767384177
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0010
5.948378146487871
9.544413714305104
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0010
6.235443652460119
9.979214042515267
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0013
6.9673477291090435
11.014408320961206
→ No improvement. Patience: 2/7
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0008
6.684636757366909
10.60671252452775
→ No improvement. Patience: 3/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0008
6.036156735281197
9.758252436456775
→ No improvement. Patience: 4/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0008
5.979798396298796
9.64090967612149
→ No improvement. Patience: 5/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0008
5.6821532679033036
9.261256829651838
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.492857818317399
8.959091171265333
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.088736017250331
8.404735098530413
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0010
5.114884610539631
8.442296028377932
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0013
5.361738160142969
8.721856216771764
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0012
5.5430768083350594
8.998704287046653
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0011
5.0310814894710765
8.306616229512874
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0010
4.818394010875076
8.026071931608142
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.756990107829923
7.984174317365383
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.7008933582319194
7.918143713358591
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
4.816761907633016
8.068226305657259
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.734069479030354
7.95624739246422
→ No improvement. Patience: 2/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.923958030721459
8.189382241257006
→ No improvement. Patience: 3/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.530522077213677
7.625454426960898
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0009
4.962515885969012
8.177823453210532
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
4.970422087864602
8.189247204420047
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
5.3054435838927665
8.650359861065194
→ No improvement. Patience: 3/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0009
5.008223764292074
8.23870811462083
→ No improvement. Patience: 4/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
4.738448640745654
7.893462459075094
→ No improvement. Patience: 5/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0008
4.507836853740259
7.550083266126972
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.402976821436757
7.419954197732804
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0008
4.211962146426318
7.166914658433549
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0007
4.407360477179114
7.4799492555713645
→ No improvement. Patience: 1/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0008
4.167688127158482
7.1518906101488176
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0007
4.215649914698855
7.163532484264326
→ No improvement. Patience: 1/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
4.179444440425539
7.171708083969343
→ No improvement. Patience: 2/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0008
4.110662604981494
7.051316576474596
→ Model improved. Saving...
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0008
4.245133467501155
7.232997813421359
→ No improvement. Patience: 1/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0008
5.988667627045377
9.483372501838222
→ No improvement. Patience: 2/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0008
5.076341275394753
8.32620088792954
→ No improvement. Patience: 3/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0008
4.30133012417246
7.306142171193925
→ No improvement. Patience: 4/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0008
4.206453238820495
7.1564797723617515
→ No improvement. Patience: 5/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0008
4.1246861181682
7.053612785151281
→ No improvement. Patience: 6/7
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0008
4.074204566914058
6.982106936141007
→ Model improved. Saving...
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0008
4.090631073254062
7.009905970321433
→ No improvement. Patience: 1/7
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0007
3.968359675725154
6.836156703292726
→ Model improved. Saving...
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0007
4.064822414890399
6.983670583983164
→ No improvement. Patience: 1/7
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0008
4.0346475957792896
6.917184367277102
→ No improvement. Patience: 2/7
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0007
4.026572710614627
6.90850402844644
→ No improvement. Patience: 3/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0007
4.112524144472179
7.047422739309821
→ No improvement. Patience: 4/7
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0008
4.214719799101742
7.165775140371213
→ No improvement. Patience: 5/7
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0007
3.9902046584989335
6.901501101751948
→ No improvement. Patience: 6/7
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0007
4.184135056779417
7.134272045535225
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:58 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:3.968359675725154 test_acc:6.836156703292726
Best model parameters loaded: ./model/5la.pth
Best model parameters loaded../model/5la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0064
15.08177456268711
22.404300660793343
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0026
9.327240658032485
14.030619165841946
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0023
8.142395389988563
12.42218449136459
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0021
7.635942038966596
11.70919916180647
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0019
8.287079129676084
12.604199785142331
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0018
6.108455169554758
9.535046713498492
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0017
5.788666548184337
9.109594277631455
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0017
5.38066316704255
8.539629811394587
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0016
5.2265509311955585
8.332311075547368
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0013
5.897959531634724
9.232925121872665
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0012
5.539189876952239
8.708756344434715
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0010
5.040993349366699
8.098911862923178
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0010
4.782623396639237
7.725249972444193
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0009
4.761379504030565
7.743471982781314
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0009
4.414306984948669
7.263092283042654
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0007
4.2894715961318965
7.077792420824929
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0008
4.757210039755652
7.6545782887657134
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0010
4.782158443165786
7.773940061118885
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0010
4.355030664669241
7.15512409987392
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
4.064719502223304
6.776746954417231
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
4.498436391388642
7.386175812297827
→ No improvement. Patience: 1/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
4.305816827155761
7.152147206555104
→ No improvement. Patience: 2/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
4.308799542337943
7.080317444842074
→ No improvement. Patience: 3/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0008
4.040972670581847
6.7914309761242295
→ No improvement. Patience: 4/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0007
3.959815192350567
6.65933237262523
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.295559927283661
7.157173799831972
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0010
4.074346759538449
6.742133919556948
→ No improvement. Patience: 2/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.037628775332849
6.745225747154997
→ No improvement. Patience: 3/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0007
3.77435957766466
6.417338310034709
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0007
3.8244285590402693
6.4887160674513265
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0007
4.082569694218628
6.825792394301899
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0007
3.9302875381310227
6.649859132255275
→ No improvement. Patience: 3/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0009
3.8231407564710667
6.4916202687407845
→ No improvement. Patience: 4/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0007
4.1571625276447115
6.926220407434315
→ No improvement. Patience: 5/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0009
3.5229610083775955
6.0781245929945324
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0010
4.221725456913084
6.933432767870433
→ No improvement. Patience: 1/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.443290594774278
7.233892718613039
→ No improvement. Patience: 2/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0008
4.582877013606178
7.449728826514572
→ No improvement. Patience: 3/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
4.7160543748544725
7.6216322124154905
→ No improvement. Patience: 4/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0008
4.897158766851715
7.8327592118097895
→ No improvement. Patience: 5/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0007
4.381704052649518
7.180742045540697
→ No improvement. Patience: 6/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
3.5917004848326743
6.1706542761758945
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:41 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:3.5229610083775955 test_acc:6.0781245929945324
Best model parameters loaded: ./model/6la.pth
Best model parameters loaded../model/6la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0107
30.521515112945238
44.658401333320974
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0030
12.913154916172171
19.053026985540995
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0027
10.404132707548872
15.528326950765406
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0024
9.704585318125039
14.570856131357182
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0020
9.818236276772769
14.747483345095603
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0018
9.907038620768153
14.845722132742324
→ No improvement. Patience: 2/7
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0016
9.485938413998923
14.249561077044177
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0016
8.853208782762064
13.379033790836063
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0015
8.49340085420288
12.880797559258822
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0014
8.104821903818383
12.361109329895456
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0014
7.713831938908038
11.830234298859322
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0013
7.396040609526464
11.401394825126422
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0013
7.150238103964813
11.090465162352892
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0013
6.942206166940413
10.81516854403847
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0013
6.918954175267711
10.791181520318691
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0013
6.649276017175758
10.4259266474431
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0013
6.600026140176583
10.380975299747924
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0013
6.485067842606645
10.221747984222175
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0013
6.378216982042848
10.081445135208796
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0012
6.403542709721282
10.11573384155663
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0013
6.466251482119587
10.2057622789475
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0012
6.535602057776617
10.298806113598378
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0012
6.303518357505275
9.981379390864538
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0012
6.354102308943222
10.041636537979569
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0011
6.372764314169047
10.069696662993556
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
6.2873834522605465
9.95117418790029
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
6.209664803827062
9.860024360417619
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
6.071085883765861
9.667080454385335
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
6.076446892251408
9.677314316082708
→ No improvement. Patience: 1/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0010
5.988486589190842
9.553582356675191
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0010
5.868881662248551
9.401818142976747
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
5.9000092623744536
9.439696582575786
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
5.6466358767446865
9.104536672667589
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0010
5.483621275334403
8.886293623301619
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0010
5.440991959179183
8.824250521341767
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0010
5.240812972803623
8.560155214737646
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0010
5.19051802195674
8.48903634169844
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0010
5.25720593708109
8.579979319492292
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0010
5.248581176495123
8.565263993995243
→ No improvement. Patience: 2/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0010
5.265818645311463
8.59527546627951
→ No improvement. Patience: 3/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0010
5.297184343196584
8.64203273379177
→ No improvement. Patience: 4/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0010
5.360553869634453
8.73423037359006
→ No improvement. Patience: 5/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0010
5.56353801490888
9.006391574237242
→ No improvement. Patience: 6/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0009
5.675654534225769
9.152196034327092
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:43 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:5.19051802195674 test_acc:8.48903634169844
Best model parameters loaded: ./model/7la.pth
Best model parameters loaded../model/7la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0121
32.93682073211259
48.37750472157766
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0040
14.70295436793209
21.630695912278693
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0032
11.484477765071517
17.111031342118082
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0025
10.358285898541144
15.504603514125272
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0020
9.465806918369092
14.255188169106678
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0018
8.944856302364771
13.538357662203934
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0015
8.574933671042674
13.047690534134208
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0014
8.149150555287743
12.456594925863214
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0013
7.76851549974574
11.924722521042293
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
7.309797806688191
11.289269893889792
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0012
7.148631021595745
11.072897709763387
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
6.740517870985909
10.503813275795553
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0011
6.488996375408784
10.173134177104519
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
6.237143852530409
9.84647070821937
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
6.013228061548826
9.55199656506976
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0010
5.877269517943086
9.371821317020135
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.809427735217576
9.293678664809338
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.664075894580556
9.114140927605009
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.587968988369591
9.02166517903133
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0009
5.382905497757595
8.743044638396269
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0010
5.1851763487779925
8.479678664688759
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0010
5.126875445470104
8.419008658605428
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0010
5.092302730321114
8.386971446124845
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0010
4.954632559424593
8.203684944188476
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0009
4.866792368592609
8.082811195148963
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.838865907402333
8.048651478725082
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
4.964877950252949
8.209285731614914
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
5.0029858178004085
8.269146206361675
→ No improvement. Patience: 2/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0007
5.080430535451624
8.354125375800944
→ No improvement. Patience: 3/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0007
5.043476114778431
8.32122533756018
→ No improvement. Patience: 4/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0007
5.125332955561651
8.434363198342641
→ No improvement. Patience: 5/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0007
5.076247590965542
8.357504960550877
→ No improvement. Patience: 6/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0008
4.944963553983977
8.214123964578208
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:32 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:4.838865907402333 test_acc:8.048651478725082
Best model parameters loaded: ./model/8la.pth
Best model parameters loaded../model/8la.pth
(Dropout: 0.1) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0194
34.18341959269852
50.463527717489825
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0056
15.589571393660746
23.215261334795727
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0047
12.7529322895464
19.16756777265985
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0039
11.488944532618776
17.33679991856992
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0033
10.83071749289961
16.360733875654915
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0029
10.295724297716163
15.564334111952151
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0026
9.712168893888245
14.706940287968635
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0023
9.150320644004891
13.900791595912022
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0021
8.64995889337102
13.19612026381611
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0019
8.268266004512297
12.653939299130043
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0017
7.8867958336231805
12.107863882285182
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0016
7.48385993933255
11.573379391995854
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0014
7.207394369955215
11.169403934765212
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0012
6.818427376859779
10.623770258545559
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0011
6.548602370177953
10.255933874358492
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0010
6.180039379032464
9.762728922984735
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.692802336973204
9.096296252634604
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.414512663469149
8.69915353636515
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.267183469726991
8.509995435437348
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0009
5.135045705253377
8.32090237435433
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
5.136856940974637
8.328033516742332
→ No improvement. Patience: 1/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0009
5.000781260499832
8.146868500529006
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0009
4.8984024128396495
8.02277550014702
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0008
4.872283032358686
7.991248907598647
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.704833806583888
7.769666732418826
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.676779989073442
7.7211226547558045
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
4.629440600782083
7.659361978280221
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.605532486062167
7.630854740516651
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.5503642300541545
7.546735853542242
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0007
4.459050005150452
7.436807733797011
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.420396540739228
7.389471566078879
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0007
4.478832524510103
7.484902605551795
→ No improvement. Patience: 1/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0007
4.886833463104152
8.016803970468159
→ No improvement. Patience: 2/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0007
4.649127078936822
7.693946074164047
→ No improvement. Patience: 3/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
4.264780698993868
7.204001706139698
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0008
4.184970188610375
7.092672807506063
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0007
4.140375570330305
7.039703197721936
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0007
4.131387312216868
7.028608453346626
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0007
4.132002991688904
7.035945553963161
→ No improvement. Patience: 1/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0007
3.969023722591252
6.8223990572984246
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0006
3.7606062083952523
6.5687226208756755
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
3.5874094303518143
6.356511698027131
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0006
3.6649508989912714
6.459243256231206
→ No improvement. Patience: 1/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0006
3.5986263326774846
6.379995510749666
→ No improvement. Patience: 2/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0006
3.5382722490700846
6.277075413704015
→ Model improved. Saving...
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0006
3.5547914538410925
6.286641383939463
→ No improvement. Patience: 1/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0006
3.479641522052209
6.211760589154532
→ Model improved. Saving...
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0006
3.5207905001279856
6.264252175424309
→ No improvement. Patience: 1/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0006
3.4611617489792494
6.202337884189598
→ Model improved. Saving...
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0006
3.7552584558392232
6.568835195569041
→ No improvement. Patience: 1/7
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0006
3.9799293226069117
6.834773508556073
→ No improvement. Patience: 2/7
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0006
3.881602835133883
6.70999133829382
→ No improvement. Patience: 3/7
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0006
3.78747644650239
6.576612861366527
→ No improvement. Patience: 4/7
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0006
3.396447256659303
6.126976390584199
→ Model improved. Saving...
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0006
3.296852297212341
5.991588039228362
→ Model improved. Saving...
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0006
3.1775680245665074
5.858421433835772
→ Model improved. Saving...
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0006
3.1610178824053965
5.82978436726559
→ Model improved. Saving...
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0006
3.1161100337681926
5.783987089363953
→ Model improved. Saving...
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0006
3.190623588720478
5.847754116688004
→ No improvement. Patience: 1/7
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0006
3.336994141563459
6.035075711428433
→ No improvement. Patience: 2/7
------------------------------
Epoch [61/300], Step [499/499], Loss: 0.0006
3.3919388197069646
6.064241037991148
→ No improvement. Patience: 3/7
------------------------------
Epoch [62/300], Step [499/499], Loss: 0.0006
3.3078220946740093
5.963847077258221
→ No improvement. Patience: 4/7
------------------------------
Epoch [63/300], Step [499/499], Loss: 0.0006
3.4082892123190995
6.0969913779393705
→ No improvement. Patience: 5/7
------------------------------
Epoch [64/300], Step [499/499], Loss: 0.0006
3.7088528513228005
6.479190255790978
→ No improvement. Patience: 6/7
------------------------------
Epoch [65/300], Step [499/499], Loss: 0.0006
3.834429195952951
6.628578667975449
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:64 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:3.1161100337681926 test_acc:5.783987089363953
Best model parameters loaded: ./model/9la.pth
Best model parameters loaded../model/9la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0065
31.294458843115727
45.729272950136874
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0022
12.50364897565501
18.48109400314817
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0020
10.670782555959258
16.060339337883597
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0019
9.769363480212803
14.819884337296328
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0018
9.611615803245588
14.622786267642175
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0019
10.55702798421243
15.976149314309037
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0017
8.83246853660611
13.54390665291742
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0015
8.200067551661874
12.6304715178191
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0016
8.18745996091224
12.623517946597904
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0015
8.36714225156282
12.861153042981815
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0014
8.00575558269174
12.37906592799448
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0014
7.322584579055437
11.439830161321078
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0014
7.043761877437391
11.047813169202165
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0015
7.0490356441910995
11.03408212808925
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0014
6.802053365836088
10.689660982836978
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0015
7.4903812959233225
11.674583362931205
→ No improvement. Patience: 1/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0014
7.91490162388487
12.248473583382065
→ No improvement. Patience: 2/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0015
7.519870037089702
11.6712944442187
→ No improvement. Patience: 3/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0014
7.534546071373028
11.665691011857655
→ No improvement. Patience: 4/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0015
7.419513160859843
11.500595764589574
→ No improvement. Patience: 5/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0014
7.032914494148493
10.970432603367904
→ No improvement. Patience: 6/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0014
7.434753982481437
11.52651288024641
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:21 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:6.802053365836088 test_acc:10.689660982836978
Best model parameters loaded: ./model/10la.pth
Best model parameters loaded../model/10la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0076
14.43509797913112
21.238826579559884
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0017
9.499412000692761
14.284904476414404
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0018
7.956194379920461
12.180131518097488
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0017
7.198752047214035
11.14508834840314
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0014
6.765143814728629
10.536794019053536
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0012
6.640968000249444
10.382077769203036
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0011
6.662499317649429
10.459637582882218
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0012
6.597100293792474
10.3025672057834
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0010
6.449757623731059
10.081191350653162
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0011
6.97154438015692
10.92524238067985
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0010
6.265876978677801
9.922577374049949
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0010
6.458824893383243
10.061748592154132
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
5.834345035232182
9.319490449966102
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
5.554273058504509
8.871062296379765
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
5.669680482899034
9.089485015229487
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0010
5.468590356542742
8.792210819369464
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.338104340851787
8.656357475099963
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0010
5.352705490459214
8.587939637565086
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0010
5.232300296410316
8.464418947975663
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0011
5.449724485850433
8.79217154043449
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0011
6.01178973858608
9.587608591801194
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0010
5.994866479214889
9.557159923190255
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0010
5.660023772815923
9.079791494443374
→ No improvement. Patience: 4/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0009
5.365764820673568
8.712047284644811
→ No improvement. Patience: 5/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.7894339856476105
7.9557951799853734
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
5.108433542622681
8.373707670653122
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0009
5.198465219377253
8.519988411330917
→ No improvement. Patience: 2/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
5.1120042068680105
8.44876911442011
→ No improvement. Patience: 3/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
5.121796875089565
8.364901617024442
→ No improvement. Patience: 4/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.569985294193714
7.7807849868818195
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.632264898966112
7.81652523946144
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0007
4.484772694085785
7.618941396725242
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0007
4.960758497049934
8.237400831593567
→ No improvement. Patience: 1/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0011
5.027941620632601
8.299418864133107
→ No improvement. Patience: 2/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0009
5.766730433619243
9.188929008323202
→ No improvement. Patience: 3/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0009
5.101204725514536
8.363553572340729
→ No improvement. Patience: 4/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.540785357695533
7.632345530084227
→ No improvement. Patience: 5/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0008
4.911788499652455
8.0934313617298
→ No improvement. Patience: 6/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
4.903679994538469
8.099924098712627
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:38 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:4.484772694085785 test_acc:7.618941396725242
Best model parameters loaded: ./model/11la.pth
Best model parameters loaded../model/11la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0065
15.469202620509158
22.678656466637715
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0036
8.896846832349027
13.482656730998693
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0027
7.5771447803669
11.624836223082424
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0021
7.606348576069136
11.707623625267336
→ No improvement. Patience: 1/7
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0019
6.412245174027416
10.017341591910427
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0016
10.257210439662892
15.382555827806488
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0013
8.145288398954214
12.473581395983112
→ No improvement. Patience: 2/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0012
6.219159709147339
9.804837251105994
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0011
5.973728337917484
9.47529269945106
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
6.229431677241083
9.907199322559595
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0013
8.516864140732746
12.932491327391187
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0017
6.915764452971048
10.709101443372147
→ No improvement. Patience: 3/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
5.609600662774887
8.866490137119538
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0011
5.366620369010063
8.562467403127277
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0017
6.520938776860167
10.080814816002311
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0013
5.285465993612709
8.440771110331765
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0011
6.392371174188595
9.916405661770769
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0011
5.286174668006243
8.462513036473704
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0010
5.353515546286936
8.45599104190276
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
6.788380359415739
10.427947836586531
→ No improvement. Patience: 4/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0021
11.642706813835805
17.33509038476432
→ No improvement. Patience: 5/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0011
6.699452871155207
10.412333010340145
→ No improvement. Patience: 6/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0009
4.893396266006278
7.91886582602602
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
4.80318630947635
7.773438987484343
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.9206534188087545
7.9805780879897315
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
5.0134575333137485
8.16251448109048
→ No improvement. Patience: 2/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0007
4.454948344718866
7.4753070234017525
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
5.263451015289315
8.479391941972239
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.18460423528025
7.125927058060144
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0009
4.755224333403868
7.886289544860087
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0009
4.405849907118843
7.4467827368853365
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0012
5.086942746925441
8.30500946681263
→ No improvement. Patience: 3/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0007
4.333617377853932
7.286675315902865
→ No improvement. Patience: 4/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0007
4.848860555987528
7.872425249414395
→ No improvement. Patience: 5/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0007
4.797855459929594
7.829228302677502
→ No improvement. Patience: 6/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0006
4.955260799616575
7.972206697431453
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:35 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:4.18460423528025 test_acc:7.125927058060144
Best model parameters loaded: ./model/12la.pth
Best model parameters loaded../model/12la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0084
50.14816795688783
72.86733475980013
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0025
11.90610569104323
17.421274601663267
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0023
10.159100573975344
15.07204877128751
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0022
9.368014398498394
14.039773207742362
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0018
8.519254570047122
12.890658641893182
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0016
7.8818223205902145
12.05185735759799
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0014
7.696086409184546
11.86465244954707
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0013
7.367765614849088
11.455973840862598
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0013
7.0762461436643935
11.099082804871472
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0013
7.02654652407878
11.078044431147191
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0014
6.8791924755509495
10.877792868571674
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0013
6.7189449938914265
10.643540730927153
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0013
6.553062469565326
10.441265658668083
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0013
6.481114688733734
10.349628756269254
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0013
6.3310110167894775
10.169336758705287
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0013
6.255813593262796
10.068476464456396
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0013
6.259134649148054
10.071260887223456
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0013
6.224964327843513
10.01553167152104
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0013
6.192767502822767
9.993062008316468
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0013
6.414420296486708
10.278943414273792
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0013
6.945708710114193
10.975339432949603
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0012
7.230517807165649
11.35218273493183
→ No improvement. Patience: 3/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0011
6.586234861834081
10.440831393179867
→ No improvement. Patience: 4/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0010
6.227330906492894
9.941571801700885
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0011
6.161244555242198
9.853286159421865
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
6.22866202973661
9.945049654385203
→ No improvement. Patience: 1/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
6.3126862230930385
10.060807543744005
→ No improvement. Patience: 2/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0011
6.306466783643168
10.038261019448804
→ No improvement. Patience: 3/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0011
6.268451418386364
9.975111416604284
→ No improvement. Patience: 4/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0011
5.945651640608996
9.551623631604782
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0011
5.878635799482808
9.451883784913331
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
5.546147004055149
9.01860960321071
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
5.370680529819749
8.793460724821815
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0010
5.233271915497534
8.585434349519558
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0010
5.234281231888803
8.581982287584532
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0011
5.37130559296536
8.755195838220123
→ No improvement. Patience: 1/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0012
5.543396151902186
8.980589723360827
→ No improvement. Patience: 2/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0013
6.134973200163005
9.767299879829531
→ No improvement. Patience: 3/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0012
6.264105954377488
9.93128004437818
→ No improvement. Patience: 4/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0012
6.085562384453533
9.681668171827125
→ No improvement. Patience: 5/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0012
6.06976315308722
9.65680301723781
→ No improvement. Patience: 6/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0012
5.849474940794125
9.383614521532136
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:41 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:5.234281231888803 test_acc:8.581982287584532
Best model parameters loaded: ./model/13la.pth
Best model parameters loaded../model/13la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0099
27.596798095853014
40.485743633058846
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0026
10.743595620035249
16.067407569028518
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0017
8.541191327919336
12.969681392829461
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0016
7.784148049756079
11.95397340216245
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0016
7.634189461064501
11.746875281673763
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0013
7.271090865298953
11.237635148528664
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0013
7.607577496198236
11.71381158160492
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0011
6.262537101294267
9.82597962620122
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0010
6.1465569722503455
9.699775451163593
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0010
5.922541877816779
9.418381081124243
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0010
6.277860954090838
9.896051423150418
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.899583631675372
9.426301833710511
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0014
5.779462184252955
9.218908065585879
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
6.595595703665874
10.449714941236383
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0008
5.989469167653783
9.557020551347504
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0008
5.678315984086896
9.112813480768137
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.483274381074244
8.855720920988894
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.37320915108601
8.7276868357465
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.189674711563708
8.484242393763553
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0009
5.34606797771393
8.710680642423528
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
5.252996065430511
8.54477562195715
→ No improvement. Patience: 2/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0009
4.916166842852638
8.116911744924431
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
5.038913544376579
8.170383141067193
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0009
4.747541128025782
7.798448404167886
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.547737900034862
7.53639933780747
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.482249068537753
7.492155101154071
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
4.420131369024518
7.426744770672712
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.497487997991222
7.552406553230647
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.561087594188038
7.64125865165725
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.646040230733203
7.7539203361280284
→ No improvement. Patience: 3/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.507399001614669
7.590292959092161
→ No improvement. Patience: 4/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0008
4.383499082054262
7.365292990817134
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0008
4.413248534689094
7.420504568133192
→ No improvement. Patience: 1/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0009
4.533255627799127
7.590761616733577
→ No improvement. Patience: 2/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0007
4.252001698925842
7.204345934255166
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0008
4.265995837368591
7.276744886846406
→ No improvement. Patience: 1/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.305255224509764
7.328407965280611
→ No improvement. Patience: 2/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0008
4.196465976369331
7.1547702313854495
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
4.053747925546686
6.9429055095278125
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0007
4.000653083856175
6.888868698288396
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0007
3.983874276815887
6.865474239521988
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0008
4.008211041806371
6.897818374151049
→ No improvement. Patience: 1/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0008
4.041411007773569
6.955030081338904
→ No improvement. Patience: 2/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0008
4.144032313874804
7.096463436798792
→ No improvement. Patience: 3/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0007
4.187798098088443
7.169216721084396
→ No improvement. Patience: 4/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0008
4.333880157509834
7.346464957897519
→ No improvement. Patience: 5/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0008
4.212524441351282
7.175320010230549
→ No improvement. Patience: 6/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0008
4.31584598850724
7.352942514564775
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:47 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:3.983874276815887 test_acc:6.865474239521988
Best model parameters loaded: ./model/14la.pth
Best model parameters loaded../model/14la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0062
16.18865251345545
23.834910228747464
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0028
9.568992462007849
14.394085470951959
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0018
8.809804703610203
13.352665049127156
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0015
6.997167789058948
10.804259894535582
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0016
7.015044644431569
10.868091146878388
→ No improvement. Patience: 1/7
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0015
6.257577529877832
9.825503237728515
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0015
5.94651648131652
9.42696033017711
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0014
5.524680610062404
8.848370971491791
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
5.354746538598517
8.65250406205854
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
5.216862491902368
8.480906574696238
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0012
5.408424181543561
8.723695309301956
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.141037001263198
8.373572034435831
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0011
4.822296205582671
7.904189991717495
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
5.465431294435969
8.714944295590852
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
4.938436451916363
8.021972076096382
→ No improvement. Patience: 2/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0008
4.596532343247313
7.630145292488357
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0008
4.6901581825535725
7.760734315527021
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
4.882239654969965
7.9441128128150105
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
4.97201578327525
8.115963753028957
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
4.8885638120475665
7.98693626510467
→ No improvement. Patience: 4/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0007
4.673586750819819
7.655097866394509
→ No improvement. Patience: 5/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
4.616651742876334
7.560283517743115
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0007
4.077864291349047
6.94423636435729
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0008
4.18060967899439
6.998967288791806
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.15006881929726
7.088901081732824
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0007
4.412334675718659
7.395716060391655
→ No improvement. Patience: 3/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0007
4.1639613750809055
7.078376495405002
→ No improvement. Patience: 4/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0006
4.093701952807013
6.997371042172387
→ No improvement. Patience: 5/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0007
3.9024642334854844
6.700579739421858
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0007
4.069160529544675
6.98349574007555
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0007
4.445702775467254
7.347934190406142
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
4.224660552478287
7.078067216261359
→ No improvement. Patience: 3/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0006
4.016440295925414
6.830678860265086
→ No improvement. Patience: 4/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0008
4.896929727775891
8.010601654100052
→ No improvement. Patience: 5/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
4.944710995165085
8.016670233822971
→ No improvement. Patience: 6/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0007
4.026321520636278
6.785409850706409
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:35 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:3.9024642334854844 test_acc:6.700579739421858
Best model parameters loaded: ./model/15la.pth
Best model parameters loaded../model/15la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0142
79.60774939622024
116.0200077389385
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0046
16.18799329390607
23.831252431130924
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0033
13.896325569809582
20.485551707926717
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0029
11.643782902591015
17.270103837739775
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0026
10.579917831659403
15.685135859804118
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0024
9.915813184054208
14.713514051841837
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0022
9.66139347541183
14.346925851392182
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0021
9.18796922232362
13.673621695411397
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0019
8.679632534687668
12.976244616218233
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0018
8.313283297664713
12.490414598592155
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0017
7.9682912739820475
12.037941400040847
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0016
7.714159824995205
11.690967873009892
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0016
7.425792108932997
11.315939440699804
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0015
7.196910980416406
11.006571592467717
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0015
6.921230611060312
10.635777409824088
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0014
6.783593823081521
10.468266287012113
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0014
6.66178591537575
10.288819472233428
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0014
6.573663391999628
10.172652265043144
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0014
6.402415428047548
9.94336309591605
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0013
6.2576842391478955
9.766826667202874
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0013
6.194917710127917
9.692374005198856
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0013
6.077259364975251
9.542832117714346
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0012
5.992087246926218
9.429330549926995
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0012
5.925218099093857
9.374262677423932
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0012
5.81412758962809
9.240708385232958
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0012
5.790626125026915
9.209030073333922
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
5.670992562866642
9.058048482051818
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0012
5.657660841964928
9.045434636108542
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0011
5.576706043198365
8.952378808762031
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0011
5.559006294459433
8.936292659445193
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0011
5.492418958745795
8.859462389065655
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0011
5.430240379714388
8.778953837954369
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0011
5.386690654936762
8.73293619319463
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0011
5.3059046381778865
8.623714666417627
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0011
5.298327805934062
8.630633262574817
→ No improvement. Patience: 1/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0011
5.244527140738896
8.555808592823675
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0011
5.332291424436015
8.661325527200926
→ No improvement. Patience: 1/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0011
5.389231274329741
8.74039639212617
→ No improvement. Patience: 2/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0009
5.221293414213458
8.52793182896927
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0010
5.075206341337574
8.35100302208985
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0009
5.0457075739527495
8.31259573065876
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0009
4.994530216753744
8.257454256692982
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0009
4.971527817593156
8.21968812457359
→ Model improved. Saving...
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0009
4.977826049583658
8.229692584411207
→ No improvement. Patience: 1/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0009
4.977082769183558
8.227433415366804
→ No improvement. Patience: 2/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0009
4.90467912983739
8.134911672170643
→ Model improved. Saving...
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0009
4.880738755655897
8.1047452435997
→ Model improved. Saving...
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0009
4.846100606791507
8.059983457106865
→ Model improved. Saving...
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0009
4.805380200715494
8.028160884779062
→ Model improved. Saving...
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0009
4.772994280386482
7.996525839479975
→ Model improved. Saving...
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0009
4.731252035749687
7.943775316440215
→ Model improved. Saving...
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0009
4.710029761846075
7.9138985986050265
→ Model improved. Saving...
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0009
4.67003149726326
7.869964331150622
→ Model improved. Saving...
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0009
4.68725996001177
7.897414489057163
→ No improvement. Patience: 1/7
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0009
4.763269159866664
7.981401418675317
→ No improvement. Patience: 2/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0009
4.7263159419184335
7.9415723490638515
→ No improvement. Patience: 3/7
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0010
4.8016125947475725
8.040354258568957
→ No improvement. Patience: 4/7
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0010
5.046708137936587
8.346095754908704
→ No improvement. Patience: 5/7
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0010
4.881056496712219
8.136609730637048
→ No improvement. Patience: 6/7
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0010
4.677412367296434
7.8783256917571824
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:59 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:4.67003149726326 test_acc:7.869964331150622
Best model parameters loaded: ./model/16la.pth
Best model parameters loaded../model/16la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0124
51.345167018642165
75.08228184058194
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0036
13.992213078709346
20.652103790416795
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0027
11.64886242454046
17.424853279941885
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0021
9.645649478890846
14.604596206784459
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0018
8.795195940249583
13.348453369535317
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0016
8.425845260479477
12.851240151652444
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0014
8.31594203726597
12.694871857920402
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0013
8.128617293460735
12.421432771547613
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
7.973016039707668
12.209012437117309
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0011
7.478608889241773
11.536964705798411
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0011
7.07352535418833
10.996596477909264
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
6.689111458959002
10.477379225802178
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0010
6.390240718640044
10.092749462060505
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
6.028326554952627
9.62694479842364
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
5.829286473795544
9.371730907417186
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0009
5.5963369532842115
9.06805552099213
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.455548458141709
8.879043273273714
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.264457900309826
8.635749445447189
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.254336247492246
8.6288366815438
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
5.138045784402474
8.474591755573343
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0008
5.205734782564273
8.555817814079203
→ No improvement. Patience: 1/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
5.064468461796138
8.368407448779205
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
4.981038683352877
8.269485157075753
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0008
5.002179712250741
8.293963038409492
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
5.114867985312155
8.435525763147975
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0007
5.0291154476566655
8.312316111612384
→ No improvement. Patience: 3/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0007
4.9733705191150905
8.239067579214838
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0007
5.234674599059131
8.550745191020171
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0007
4.650737728513998
7.802285862894608
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0007
4.591716601712939
7.725095789832789
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0006
4.607701858120074
7.729687355141737
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0006
4.622131278366627
7.755597986147298
→ No improvement. Patience: 2/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0006
4.5874530901180774
7.695323156410201
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0006
4.452748827721144
7.5372428379004655
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0006
4.376880312889779
7.454228323122272
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0007
4.217576682574516
7.265293871326104
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0007
4.12876851887592
7.16691869920818
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0007
4.090790208620069
7.119158631705553
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0007
4.057332966682364
7.0853456250935745
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0007
4.127643652392065
7.20057385323017
→ No improvement. Patience: 1/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0008
4.482239059317208
7.664968619588339
→ No improvement. Patience: 2/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
4.4258109296016395
7.596384088973593
→ No improvement. Patience: 3/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0007
4.2312593757594135
7.335266087079896
→ No improvement. Patience: 4/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0007
3.954072303547884
6.974622322916109
→ Model improved. Saving...
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0007
3.830027632759778
6.799128656915002
→ Model improved. Saving...
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0007
3.7606497961531633
6.691076708817466
→ Model improved. Saving...
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0007
3.8165871632292454
6.751858761666656
→ No improvement. Patience: 1/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0006
3.8163464965406564
6.743420750002412
→ No improvement. Patience: 2/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0007
3.762260542965216
6.681415414069565
→ Model improved. Saving...
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0007
3.7522769999236387
6.662787805970552
→ Model improved. Saving...
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0006
3.694434702386992
6.589600513660571
→ Model improved. Saving...
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0006
3.76240153376648
6.661353152678627
→ No improvement. Patience: 1/7
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0006
3.7075975997551676
6.594608249842639
→ No improvement. Patience: 2/7
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0006
3.7609541865379903
6.657558523484403
→ No improvement. Patience: 3/7
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0006
3.796775156221833
6.702822441467639
→ No improvement. Patience: 4/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0006
3.680568352518346
6.558843067949476
→ Model improved. Saving...
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0007
3.5045028568391654
6.342309229879795
→ Model improved. Saving...
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0007
3.725833555844889
6.631081483085563
→ No improvement. Patience: 1/7
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0007
3.9997740021709927
6.977842366976792
→ No improvement. Patience: 2/7
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0007
4.351339369293887
7.414308806620077
→ No improvement. Patience: 3/7
------------------------------
Epoch [61/300], Step [499/499], Loss: 0.0007
4.326709485458509
7.375352865109869
→ No improvement. Patience: 4/7
------------------------------
Epoch [62/300], Step [499/499], Loss: 0.0007
4.05808916360366
7.041502498309399
→ No improvement. Patience: 5/7
------------------------------
Epoch [63/300], Step [499/499], Loss: 0.0007
3.889353363920872
6.834511378522125
→ No improvement. Patience: 6/7
------------------------------
Epoch [64/300], Step [499/499], Loss: 0.0006
3.5698468215307995
6.422053276240254
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:63 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:3.5045028568391654 test_acc:6.342309229879795
Best model parameters loaded: ./model/17la.pth
Best model parameters loaded../model/17la.pth
(Dropout: 0.2) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0243
29.944673312935794
44.14636295125052
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0042
15.120644748595302
22.47873794459285
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0036
11.370586526599453
17.105559160357092
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0034
10.21091603125075
15.42732149222905
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0028
9.475794347530119
14.352472500469744
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0024
8.956583526988917
13.613072102876245
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0021
8.284454759838995
12.663892006574446
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0019
7.794165598903234
11.970321123075458
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0017
7.376074646797744
11.373240707134793
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0015
6.986990151647645
10.816651154696784
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0014
6.708076286604
10.42515582415902
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0013
6.3181445684488695
9.892017064790801
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
5.905257264729724
9.337110650708528
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0011
5.638754614614633
8.98168761835408
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0011
5.382743024294087
8.63861579352745
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0011
5.280413815562861
8.497504773672784
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0011
5.165017577820168
8.34112794707511
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0011
5.02674600373594
8.169932885595665
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0010
5.027455551353362
8.17029864759242
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0010
4.9008882181353
8.007125802280152
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0010
4.815207113411777
7.913074569999427
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0010
4.804910789795885
7.901366925318819
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0010
4.640902467160416
7.681605141017257
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
4.968912387713746
8.086682909368701
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0009
5.66066888918721
8.985628505857544
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
5.505908573742096
8.7833335650378
→ No improvement. Patience: 3/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
5.101455901277538
8.25727918433984
→ No improvement. Patience: 4/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.776972800069665
7.82826558377213
→ No improvement. Patience: 5/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.2646490104831996
7.179094788860296
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.1857779715919365
7.081101634363184
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.1917796932794875
7.090227400776093
→ No improvement. Patience: 1/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0008
4.1128175191197265
6.995955310812494
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0008
4.055042157098539
6.919933571846207
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0007
3.983203454960876
6.817800280665892
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0007
3.8746723099203395
6.678371019148782
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0008
3.9951015533075926
6.809802511777424
→ No improvement. Patience: 1/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
3.903747146038491
6.687011497706611
→ No improvement. Patience: 2/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0009
4.143294751120125
6.993351796469053
→ No improvement. Patience: 3/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
5.14597683382804
8.312276190434629
→ No improvement. Patience: 4/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0007
4.0687025027705666
6.885556484008626
→ No improvement. Patience: 5/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0007
3.896587057655177
6.666533784516203
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
3.710314224278519
6.431337326897842
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0007
3.75683088060796
6.4814601190741135
→ No improvement. Patience: 1/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0007
3.905841162707023
6.669856949607958
→ No improvement. Patience: 2/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0007
3.603105278913593
6.291406707877888
→ Model improved. Saving...
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0007
3.3956070628380735
6.048996738528349
→ Model improved. Saving...
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0007
3.2954798021587552
5.925481834467349
→ Model improved. Saving...
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0007
3.2545348682964215
5.878543580833145
→ Model improved. Saving...
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0007
3.3215517471257594
5.9432095271060525
→ No improvement. Patience: 1/7
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0006
3.3174956623394345
5.938570466803899
→ No improvement. Patience: 2/7
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0007
3.3391288190545163
5.964899010059198
→ No improvement. Patience: 3/7
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0006
3.512468614282987
6.161023135079524
→ No improvement. Patience: 4/7
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0007
3.253297407040076
5.8435278380721885
→ Model improved. Saving...
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0007
3.0372838340112835
5.590361894382199
→ Model improved. Saving...
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0008
4.140581310990371
6.9686958256173925
→ No improvement. Patience: 1/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0007
4.288575178771639
7.147826692660417
→ No improvement. Patience: 2/7
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0006
3.5685251424305826
6.180782575689284
→ No improvement. Patience: 3/7
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0008
4.5998450738453105
7.482234778105304
→ No improvement. Patience: 4/7
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0007
4.298932460036365
7.1249439689207135
→ No improvement. Patience: 5/7
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0007
3.9509718836281933
6.684215381031951
→ No improvement. Patience: 6/7
------------------------------
Epoch [61/300], Step [499/499], Loss: 0.0007
4.01130561406221
6.735514057779653
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:60 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:3.0372838340112835 test_acc:5.590361894382199
Best model parameters loaded: ./model/18la.pth
Best model parameters loaded../model/18la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0127
54.72846711132497
79.4958272752257
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0024
12.361250779286607
17.987910871247315
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0022
10.261835026026608
15.116903820928243
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0019
9.666361836863068
14.336578163524347
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0018
9.095631739358282
13.568335246448711
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0017
8.916055809844488
13.349582439627182
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0015
8.764127513980775
13.135714244198834
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0014
8.578643271522123
12.944366916351177
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
8.059610163391348
12.271768069246292
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0013
7.9138930313050455
12.105273491738773
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0013
7.811090661894119
11.992124181154177
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0013
7.719803865620925
11.870471077746062
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0013
7.502378900341281
11.550178266003414
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0014
7.463336917128236
11.524149719453728
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0014
7.579689728928272
11.691554937182126
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0014
7.306007506166022
11.303405455940974
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0012
7.51542522277119
11.644718484754454
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0012
7.068118783372291
11.045047943098563
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0012
6.9210320466792075
10.82549668628282
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0013
7.011476139429527
10.978164676982704
→ No improvement. Patience: 1/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0012
6.753967676287265
10.641884551594229
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0012
6.854289666873182
10.739317356998372
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0012
6.723355055928678
10.58807607905005
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
6.549402665718409
10.375332320868115
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0011
6.613998211595252
10.436877734887368
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
6.256616787003895
9.94416293187319
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0010
6.138374534852868
9.790560771758216
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
6.200617804578386
9.879691709449226
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
6.112123070742984
9.775560291297106
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0010
6.14319126613401
9.774843882273004
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0010
6.052653007258526
9.664452600462907
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0011
6.021974040698217
9.636307464016303
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0011
6.233090911672257
9.989987381398164
→ No improvement. Patience: 1/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0011
6.170328583588304
9.888655706458565
→ No improvement. Patience: 2/7
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0011
6.1139309746372525
9.779180606824337
→ No improvement. Patience: 3/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0010
5.928038855548116
9.566792852619932
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0012
6.656800727572176
10.500767187079411
→ No improvement. Patience: 1/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0011
6.413893847767948
10.14026724606877
→ No improvement. Patience: 2/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0011
6.289790809251149
9.970599089250998
→ No improvement. Patience: 3/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0011
6.132689051913717
9.787636673132655
→ No improvement. Patience: 4/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0011
5.841898072791473
9.347158306826701
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0010
5.981430611874929
9.549824832366877
→ No improvement. Patience: 1/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0010
5.940934995160376
9.509399333519852
→ No improvement. Patience: 2/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0010
5.94836742845193
9.531364022075058
→ No improvement. Patience: 3/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0010
5.942950226063787
9.507292874890101
→ No improvement. Patience: 4/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0010
6.023124467499499
9.640769035568757
→ No improvement. Patience: 5/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0009
6.249503835460859
9.93310960252334
→ No improvement. Patience: 6/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0009
6.107490982366973
9.754300430161235
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:47 batch_size64 lr:0.001 kernel_size3 stride:1 train_acc:5.841898072791473 test_acc:9.347158306826701
Best model parameters loaded: ./model/19la.pth
Best model parameters loaded../model/19la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0106
19.471766225599165
28.528978680032438
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0020
8.710601370838067
13.167486770997998
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0017
8.082140775188611
12.360376972894667
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0015
7.489251675450642
11.545083885660212
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0014
6.676017210717079
10.490267158690816
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0012
6.597495291015373
10.376939544808085
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0010
6.571426630183376
10.37339472159517
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0011
6.193665227310768
9.887652399197023
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0011
6.961096731144764
10.876463255342204
→ No improvement. Patience: 1/7
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0011
5.8665717600394975
9.407250255819864
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0010
5.772295510522692
9.264946035797328
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
6.3151104807401275
9.957819140471297
→ No improvement. Patience: 1/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0010
8.731627397099242
13.4512944226282
→ No improvement. Patience: 2/7
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0011
5.713351353642412
9.163943761156727
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0009
6.904693598793175
10.76485531351788
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0009
5.269326451252008
8.552682824643206
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
7.0187688876582115
10.98909654715344
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0010
6.258028069960996
9.940150517144168
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0013
5.56239104836213
9.012781288306543
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
8.190638265816128
12.630015974791531
→ No improvement. Patience: 4/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
5.787953064610248
9.331415130285288
→ No improvement. Patience: 5/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0014
5.281224593172616
8.52701288407383
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0010
4.851310178297079
7.976535524281733
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
5.667390276421069
9.070629874390395
→ No improvement. Patience: 1/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0012
6.3717948832869755
10.06577704155629
→ No improvement. Patience: 2/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0010
5.635068816027183
9.014072120943545
→ No improvement. Patience: 3/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0009
5.787835893507846
9.285208211059803
→ No improvement. Patience: 4/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
6.258950836578997
9.82344677767072
→ No improvement. Patience: 5/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
5.019004938586753
8.284185691049492
→ No improvement. Patience: 6/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0009
5.452715219305721
8.691125214392484
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:29 batch_size64 lr:0.001 kernel_size5 stride:1 train_acc:4.851310178297079 test_acc:7.976535524281733
Best model parameters loaded: ./model/20la.pth
Best model parameters loaded../model/20la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0078
17.400377142320078
25.731373494910073
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0025
8.70409928872637
13.034470487982599
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0020
7.938392284973705
11.970106182307253
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0015
7.497003704178957
11.387436118950362
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0012
7.080117385101782
10.84262307118527
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0011
6.647053557634185
10.28857869334287
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0009
7.025409483017366
10.89161185103043
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0013
6.837817387593103
10.584939868161523
→ No improvement. Patience: 2/7
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
6.229053647212397
9.709773830593951
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
5.860976419124048
9.205684700636281
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0009
5.804518281547151
9.252323338955076
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0014
5.936247908142603
9.28073607790395
→ No improvement. Patience: 2/7
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0012
6.317500179856263
9.852642710288526
→ No improvement. Patience: 3/7
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0012
5.926189587711099
9.295641873851663
→ No improvement. Patience: 4/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0011
6.183057304294921
9.671022105131856
→ No improvement. Patience: 5/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0009
5.54168570720612
8.717274412373461
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
5.50787181399234
8.738841541333157
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0010
5.502288395971027
8.730363387609605
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0010
5.026213869252192
8.140892692123002
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
4.622152176079698
7.555976073818752
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0007
4.492745404582467
7.372299376300707
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0010
4.4431815191303645
7.359152296239052
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0007
5.472334569523258
8.633107034761824
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0012
5.207920738222116
8.34741833693866
→ No improvement. Patience: 2/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
4.836309272209719
7.9297076381445475
→ No improvement. Patience: 3/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
5.223964426572136
8.389681646929912
→ No improvement. Patience: 4/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0006
4.448672958611974
7.362629397431081
→ No improvement. Patience: 5/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0009
4.609242427478259
7.590682474611242
→ No improvement. Patience: 6/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0009
4.658951695979248
7.73902088669098
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:28 batch_size64 lr:0.001 kernel_size7 stride:1 train_acc:4.4431815191303645 test_acc:7.359152296239052
Best model parameters loaded: ./model/21la.pth
Best model parameters loaded../model/21la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0105
67.59092706439651
98.15141927661044
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0035
11.381384631527299
16.83163494767878
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0021
10.937759340496486
16.151287937001975
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0020
9.390413587869386
14.025796987259705
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0022
9.00337387764901
13.50863856353997
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0019
9.447351334672568
14.227117042437923
→ No improvement. Patience: 1/7
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0017
9.241742197115427
13.950057147284339
→ No improvement. Patience: 2/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0015
9.324056886018639
14.066733089222435
→ No improvement. Patience: 3/7
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0014
8.873436608208737
13.43522595401353
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0015
8.762191779606011
13.237122665219827
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0015
7.819042324347103
11.94790575389396
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0014
7.556221846277734
11.584541257114957
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0013
7.015334678424983
10.834401303094841
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0012
7.069728234517599
10.936454726336342
→ No improvement. Patience: 1/7
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0012
6.851046706671191
10.630921116896523
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0012
6.808557290298021
10.569355128531896
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0011
6.729672587161471
10.465635558691782
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0011
6.610966936867591
10.308378381537269
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0011
6.710185337181397
10.43289202404203
→ No improvement. Patience: 1/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0011
6.686821027229582
10.37905577089466
→ No improvement. Patience: 2/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0011
6.595054520145813
10.26650158877556
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0011
6.676330420425415
10.365544332263369
→ No improvement. Patience: 1/7
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0011
6.691493599814218
10.429709780132914
→ No improvement. Patience: 2/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
6.923196509952517
10.717526080333263
→ No improvement. Patience: 3/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0011
6.720124643523819
10.48905929535566
→ No improvement. Patience: 4/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
7.235667216631302
11.204107369860246
→ No improvement. Patience: 5/7
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
7.390880934509778
11.437284330626987
→ No improvement. Patience: 6/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0010
6.301297972481889
9.936368836087283
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
6.17230996811612
9.759622990102036
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0010
5.989288303943431
9.514921051410223
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0010
5.940773634683226
9.467412421229513
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
5.8757972458955035
9.389916247622727
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0011
5.8245421337615015
9.35185595197679
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0010
5.66042028109932
9.13147805215428
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0010
5.733749720363714
9.24695554707968
→ No improvement. Patience: 1/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0010
5.685062200161829
9.18349990255957
→ No improvement. Patience: 2/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0011
5.595746116480172
9.050988094879536
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0010
5.375027338238118
8.805610017879676
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0010
5.214173092781268
8.570371680803996
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0010
5.103605931794399
8.435189278424135
→ Model improved. Saving...
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0010
4.944770795894998
8.212236376830779
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0010
4.919132140443359
8.194342861060305
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0010
4.888400942384564
8.127916944440319
→ Model improved. Saving...
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0010
4.894583206472207
8.15137519950848
→ No improvement. Patience: 1/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0010
4.928577295507663
8.192293802581702
→ No improvement. Patience: 2/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0009
4.932850521541504
8.187823165841136
→ No improvement. Patience: 3/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0009
5.058890621420792
8.354302649706373
→ No improvement. Patience: 4/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0009
4.935851846716413
8.19712380632498
→ No improvement. Patience: 5/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0009
4.937980708711925
8.193479457940867
→ No improvement. Patience: 6/7
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0009
5.047864038028089
8.336410153659685
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:49 batch_size64 lr:0.0005 kernel_size3 stride:1 train_acc:4.888400942384564 test_acc:8.127916944440319
Best model parameters loaded: ./model/22la.pth
Best model parameters loaded../model/22la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0082
26.502790942627254
38.8924556441728
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0019
9.378780308780614
14.007605213153145
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0014
7.859779547885422
12.02124592130249
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0012
7.087326965928973
10.970537501033611
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0011
6.676472405196148
10.384949315089607
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0011
6.174051093382244
9.747298759408189
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0011
5.88346346112973
9.392821622228347
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0010
5.722984193221014
9.151842847381625
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0010
5.5320689344349825
8.890620752586111
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0010
5.985427356999371
9.492388481906897
→ No improvement. Patience: 1/7
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0008
5.633502805291732
9.038149659236431
→ No improvement. Patience: 2/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0008
5.033055099234976
8.200780628537473
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0008
4.73088310062706
7.734045101306801
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0008
4.538997119120886
7.49229431616607
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0008
4.592259572828685
7.5189001919076395
→ No improvement. Patience: 1/7
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0008
4.646453335080183
7.578753446702793
→ No improvement. Patience: 2/7
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
4.826866880453797
7.793058013858799
→ No improvement. Patience: 3/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.153584246820922
8.276223820028331
→ No improvement. Patience: 4/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
4.839006115404799
7.884661779791411
→ No improvement. Patience: 5/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0009
4.704144019719572
7.701831457828311
→ No improvement. Patience: 6/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
4.722041949960048
7.729821435912482
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:20 batch_size64 lr:0.0005 kernel_size5 stride:1 train_acc:4.538997119120886 test_acc:7.49229431616607
Best model parameters loaded: ./model/23la.pth
Best model parameters loaded../model/23la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0005)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0126
22.920068606094883
33.67673744483092
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0036
10.688037367575076
16.13063671449211
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0021
8.934185090966444
13.652193982614195
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0018
7.768674911910574
11.989877487187233
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0017
7.211452362379534
11.147481486539998
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0016
6.660452331836118
10.39386389181153
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0014
6.894359147109346
10.764956404035896
→ No improvement. Patience: 1/7
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0012
5.820139211696374
9.261404254037137
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0012
5.661401126725448
9.06299107168406
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
5.3496362966238005
8.649892056092714
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0010
5.420847956406131
8.726707342704035
→ No improvement. Patience: 1/7
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.281370548569718
8.576623866185214
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0008
6.855061657824104
10.84909477110257
→ No improvement. Patience: 1/7
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0009
5.213187129057056
8.49435992626689
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0008
4.910783507742749
8.070193949447885
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0008
4.651075178027936
7.743579536022016
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0007
4.723100663378614
7.870050853478783
→ No improvement. Patience: 1/7
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0010
4.931626619199845
8.14257468667822
→ No improvement. Patience: 2/7
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0008
4.785514103184543
7.923565472040558
→ No improvement. Patience: 3/7
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
4.687597172414904
7.822156101152531
→ No improvement. Patience: 4/7
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0009
4.764929468409034
7.912508429872769
→ No improvement. Patience: 5/7
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0009
4.66475288647352
7.690753371424283
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
5.478416809649888
8.869298948110892
→ No improvement. Patience: 1/7
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0007
4.722012617227151
7.866302051227647
→ No improvement. Patience: 2/7
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
5.094149548264947
8.320668992139105
→ No improvement. Patience: 3/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
4.315808954721225
7.283461369835067
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
4.221434814448523
7.165217129629507
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0007
4.484380553578202
7.486042049015441
→ No improvement. Patience: 1/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0009
5.385147341207524
8.733209280540503
→ No improvement. Patience: 2/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.369398754908347
7.277768033569325
→ No improvement. Patience: 3/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0007
4.287286541673266
7.212316634107973
→ No improvement. Patience: 4/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0008
4.6297894789362255
7.6913593607207105
→ No improvement. Patience: 5/7
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0009
4.2071120137620115
7.07032865769457
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0008
4.027132528265891
6.87445503324464
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
4.680363664118109
7.713959913120629
→ No improvement. Patience: 1/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0007
5.8663583714147105
9.265554760772748
→ No improvement. Patience: 2/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0007
5.672701899093758
9.028613898190969
→ No improvement. Patience: 3/7
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0007
4.0676827790404975
6.892518257524918
→ No improvement. Patience: 4/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
4.387941590408064
7.342995791231708
→ No improvement. Patience: 5/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0008
4.277906430620125
7.15187287668397
→ No improvement. Patience: 6/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0007
4.521266371648673
7.45328644714072
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:40 batch_size64 lr:0.0005 kernel_size7 stride:1 train_acc:4.027132528265891 test_acc:6.87445503324464
Best model parameters loaded: ./model/24la.pth
Best model parameters loaded../model/24la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Epoch [1/300], Step [499/499], Loss: 0.0184
86.80869541143298
126.4568958327521
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0060
16.059021907817648
23.580348879519413
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0039
13.925420061470525
20.481138765198356
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0029
12.481270445421346
18.344790312674338
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0025
10.521563484753207
15.47700127497761
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0024
9.794737292297011
14.443678076708023
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0021
9.606483160422435
14.24513292987422
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0018
9.549770555408337
14.225549744278833
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0017
9.210086000736318
13.7556052094839
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0016
8.924481556601876
13.36285012766785
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0015
8.56580717432165
12.862566397869902
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0014
8.218071274211255
12.39042412764681
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0014
7.803683780312491
11.821667256421096
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0013
7.574553694957032
11.52138585171732
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0013
7.367037287026902
11.24413005819581
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0013
7.190408425457269
11.017622854334757
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0012
7.093575982905526
10.90211405441647
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0012
6.847598867513486
10.580875610179188
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0012
6.646927838702657
10.326795492117173
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0012
6.636608911486845
10.317609965597136
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0011
6.546198490533181
10.202530223182961
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0011
6.421546105529133
10.042781004676975
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0011
6.321973451918655
9.924028877812521
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0011
6.252689417194783
9.832463797633755
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0011
6.190074190507792
9.755700096499622
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0011
6.10214360580688
9.642946155385157
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0011
5.87647903975674
9.350295676967516
→ Model improved. Saving...
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0011
5.835238949432065
9.310081618185531
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
5.812160680264994
9.291467336919256
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0010
5.891035590645952
9.398262625756425
→ No improvement. Patience: 1/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0010
5.803301501977096
9.30013822065926
→ No improvement. Patience: 2/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0010
5.791586869054677
9.290345518156695
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0010
5.812978527466634
9.319343224371908
→ No improvement. Patience: 1/7
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0010
5.752793242894222
9.24558814180039
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0010
5.608945045683559
9.057009268318097
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0010
5.533596597551147
8.97539993763785
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0010
5.52986086304853
8.964042099945365
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0010
5.632362141304659
9.096576977199057
→ No improvement. Patience: 1/7
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0010
5.4618270051759
8.886611887413741
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0010
5.46408013556997
8.8969386241954
→ No improvement. Patience: 1/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0010
5.413369921589825
8.831482780039241
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0010
5.327294249565072
8.727070322365789
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0010
5.423364938527915
8.86335889087297
→ No improvement. Patience: 1/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0009
5.471795981529725
8.924262703956202
→ No improvement. Patience: 2/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0010
5.373620069025966
8.800509745418644
→ No improvement. Patience: 3/7
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0009
5.441881384470764
8.88348501632905
→ No improvement. Patience: 4/7
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0009
5.347851973866171
8.756779576036529
→ No improvement. Patience: 5/7
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0009
5.371865977119484
8.792446530822197
→ No improvement. Patience: 6/7
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0009
5.440691895054274
8.89613106430014
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:48 batch_size64 lr:0.0001 kernel_size3 stride:1 train_acc:5.327294249565072 test_acc:8.727070322365789
Best model parameters loaded: ./model/25la.pth
Best model parameters loaded../model/25la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Epoch [1/300], Step [499/499], Loss: 0.0187
74.07413201186233
107.85064937683701
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0038
15.782926167071173
23.36929898219846
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0028
12.705748308887456
18.95202577457382
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0023
11.000612603494208
16.555911033361156
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0020
9.726030705443474
14.69381581964122
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0018
8.984104361675112
13.600803316714087
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0016
8.535092222857239
12.977523787771036
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0014
8.236042247594765
12.573049169801656
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0013
7.944760843307707
12.18960469097008
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0012
7.610074703417871
11.735844253935726
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0011
7.217818136637556
11.201019593492198
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
6.996570885390003
10.906193786459756
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0010
6.7395871472369935
10.564631853904494
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
6.607126761669552
10.402815669900315
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0010
6.480899994149421
10.237421980355403
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0009
6.359398708113051
10.08337174041407
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
6.282187848322554
9.993501885662695
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
5.9713007446214155
9.568179485813177
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0009
5.8752723154362405
9.435035105745113
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0009
5.749206725334959
9.274649321819632
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0008
5.629333818753359
9.128785994308899
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
5.491517425167734
8.9456107978933
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
5.401043473907246
8.842514743950513
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0008
5.294546922754125
8.715261614092116
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
5.298683403076423
8.723601786261419
→ No improvement. Patience: 1/7
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
5.123472254731923
8.491882782912475
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0008
5.157795468861031
8.549046461766876
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0008
4.907195565442247
8.216956584144576
→ Model improved. Saving...
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0008
4.748623423979094
8.00344677301692
→ Model improved. Saving...
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.633704985130252
7.86366544133741
→ Model improved. Saving...
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.552877194314765
7.768781399964017
→ Model improved. Saving...
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0008
4.447797205838914
7.6279163618951245
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0008
4.341021386294498
7.499375755115419
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0008
4.247247038448003
7.374247909407211
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0008
4.2226659465578145
7.328924373447617
→ Model improved. Saving...
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0008
4.170261970780044
7.2525673535376844
→ Model improved. Saving...
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0008
4.167335310876309
7.251288775351052
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0007
4.150316234128883
7.2367066370132465
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0008
4.134949022556139
7.211052365085998
→ Model improved. Saving...
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0008
4.184867268991075
7.274120613476647
→ No improvement. Patience: 1/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0008
4.146991991076993
7.208828452151871
→ Model improved. Saving...
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0008
4.124884707435374
7.187140931665061
→ Model improved. Saving...
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0008
4.032845265418618
7.0553640477363535
→ Model improved. Saving...
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0007
3.9219406274940267
6.917492231335398
→ Model improved. Saving...
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0007
3.882334006727114
6.872291902639623
→ Model improved. Saving...
------------------------------
Epoch [46/300], Step [499/499], Loss: 0.0007
3.863396039439699
6.856008558209663
→ Model improved. Saving...
------------------------------
Epoch [47/300], Step [499/499], Loss: 0.0007
3.857338608241024
6.847514792377056
→ Model improved. Saving...
------------------------------
Epoch [48/300], Step [499/499], Loss: 0.0007
3.844759952827669
6.837083230284673
→ Model improved. Saving...
------------------------------
Epoch [49/300], Step [499/499], Loss: 0.0007
3.828188860803685
6.803981430518647
→ Model improved. Saving...
------------------------------
Epoch [50/300], Step [499/499], Loss: 0.0007
3.805384833150183
6.772014955558266
→ Model improved. Saving...
------------------------------
Epoch [51/300], Step [499/499], Loss: 0.0007
3.775098499070601
6.727609109015304
→ Model improved. Saving...
------------------------------
Epoch [52/300], Step [499/499], Loss: 0.0007
3.723210420286406
6.6533096494766895
→ Model improved. Saving...
------------------------------
Epoch [53/300], Step [499/499], Loss: 0.0008
3.9692305092577755
6.948620202164645
→ No improvement. Patience: 1/7
------------------------------
Epoch [54/300], Step [499/499], Loss: 0.0008
4.51215670039596
7.625972382709808
→ No improvement. Patience: 2/7
------------------------------
Epoch [55/300], Step [499/499], Loss: 0.0007
4.234212764235391
7.277775991365725
→ No improvement. Patience: 3/7
------------------------------
Epoch [56/300], Step [499/499], Loss: 0.0007
4.076325097865679
7.076822830789185
→ No improvement. Patience: 4/7
------------------------------
Epoch [57/300], Step [499/499], Loss: 0.0007
4.006727230641988
6.987061669655596
→ No improvement. Patience: 5/7
------------------------------
Epoch [58/300], Step [499/499], Loss: 0.0007
3.8704577355359095
6.800179272545777
→ No improvement. Patience: 6/7
------------------------------
Epoch [59/300], Step [499/499], Loss: 0.0007
3.72141430944486
6.62855429844133
→ Model improved. Saving...
------------------------------
Epoch [60/300], Step [499/499], Loss: 0.0007
3.6269215392128666
6.531425307808504
→ Model improved. Saving...
------------------------------
Epoch [61/300], Step [499/499], Loss: 0.0007
3.560707887669028
6.457751417586133
→ Model improved. Saving...
------------------------------
Epoch [62/300], Step [499/499], Loss: 0.0007
3.542219658365595
6.428168990407566
→ Model improved. Saving...
------------------------------
Epoch [63/300], Step [499/499], Loss: 0.0007
3.514448352976024
6.3984520734954415
→ Model improved. Saving...
------------------------------
Epoch [64/300], Step [499/499], Loss: 0.0007
3.5195312063881543
6.395018841799673
→ Model improved. Saving...
------------------------------
Epoch [65/300], Step [499/499], Loss: 0.0007
3.549562485279397
6.440551288916729
→ No improvement. Patience: 1/7
------------------------------
Epoch [66/300], Step [499/499], Loss: 0.0007
3.5252747021240864
6.417025806006482
→ No improvement. Patience: 2/7
------------------------------
Epoch [67/300], Step [499/499], Loss: 0.0007
3.543572847130675
6.4370415430547805
→ No improvement. Patience: 3/7
------------------------------
Epoch [68/300], Step [499/499], Loss: 0.0007
3.5363917763229122
6.425893168804589
→ No improvement. Patience: 4/7
------------------------------
Epoch [69/300], Step [499/499], Loss: 0.0007
3.6134347483637077
6.517070158819964
→ No improvement. Patience: 5/7
------------------------------
Epoch [70/300], Step [499/499], Loss: 0.0007
3.5823625951198177
6.4330380625902555
→ No improvement. Patience: 6/7
------------------------------
Epoch [71/300], Step [499/499], Loss: 0.0007
4.09336925305587
7.029526170197096
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:70 batch_size64 lr:0.0001 kernel_size5 stride:1 train_acc:3.5195312063881543 test_acc:6.395018841799673
Best model parameters loaded: ./model/26la.pth
Best model parameters loaded../model/26la.pth
(Dropout: 0.3) (kernel: [3, 5, 7]) (padding: 0) (lr:0.0001)
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Epoch [1/300], Step [499/499], Loss: 0.0225
40.90264743386383
59.84029364860065
→ Model improved. Saving...
------------------------------
Epoch [2/300], Step [499/499], Loss: 0.0049
14.430376430516903
21.659844796130745
→ Model improved. Saving...
------------------------------
Epoch [3/300], Step [499/499], Loss: 0.0034
12.21170595255545
18.33990811232279
→ Model improved. Saving...
------------------------------
Epoch [4/300], Step [499/499], Loss: 0.0026
9.880510720827317
14.938330860755451
→ Model improved. Saving...
------------------------------
Epoch [5/300], Step [499/499], Loss: 0.0023
9.027358593790801
13.687444466882827
→ Model improved. Saving...
------------------------------
Epoch [6/300], Step [499/499], Loss: 0.0022
8.13994981332153
12.391115800435
→ Model improved. Saving...
------------------------------
Epoch [7/300], Step [499/499], Loss: 0.0020
7.434339509959495
11.401780800341443
→ Model improved. Saving...
------------------------------
Epoch [8/300], Step [499/499], Loss: 0.0017
7.195000413067201
11.047073019424271
→ Model improved. Saving...
------------------------------
Epoch [9/300], Step [499/499], Loss: 0.0015
6.785606127102421
10.485315685683142
→ Model improved. Saving...
------------------------------
Epoch [10/300], Step [499/499], Loss: 0.0013
6.516323389474559
10.146249809531895
→ Model improved. Saving...
------------------------------
Epoch [11/300], Step [499/499], Loss: 0.0012
6.177666481821849
9.699495239653162
→ Model improved. Saving...
------------------------------
Epoch [12/300], Step [499/499], Loss: 0.0011
5.706674034479695
9.069980862622582
→ Model improved. Saving...
------------------------------
Epoch [13/300], Step [499/499], Loss: 0.0010
5.283670716119765
8.504481827270277
→ Model improved. Saving...
------------------------------
Epoch [14/300], Step [499/499], Loss: 0.0010
5.072114945109195
8.245756055074713
→ Model improved. Saving...
------------------------------
Epoch [15/300], Step [499/499], Loss: 0.0009
4.8827873472554515
7.992290760969882
→ Model improved. Saving...
------------------------------
Epoch [16/300], Step [499/499], Loss: 0.0009
4.66285520188109
7.729966695061733
→ Model improved. Saving...
------------------------------
Epoch [17/300], Step [499/499], Loss: 0.0009
4.591529806740572
7.651383747196825
→ Model improved. Saving...
------------------------------
Epoch [18/300], Step [499/499], Loss: 0.0009
4.409112992098326
7.41838926526628
→ Model improved. Saving...
------------------------------
Epoch [19/300], Step [499/499], Loss: 0.0008
4.30314773729332
7.291549788152638
→ Model improved. Saving...
------------------------------
Epoch [20/300], Step [499/499], Loss: 0.0008
4.210555958200036
7.195810036601878
→ Model improved. Saving...
------------------------------
Epoch [21/300], Step [499/499], Loss: 0.0008
4.084400910221685
7.037314393202994
→ Model improved. Saving...
------------------------------
Epoch [22/300], Step [499/499], Loss: 0.0008
3.9729141828152175
6.915686343162025
→ Model improved. Saving...
------------------------------
Epoch [23/300], Step [499/499], Loss: 0.0008
3.937771064359436
6.856953761015764
→ Model improved. Saving...
------------------------------
Epoch [24/300], Step [499/499], Loss: 0.0007
3.8744998810481865
6.770827960984683
→ Model improved. Saving...
------------------------------
Epoch [25/300], Step [499/499], Loss: 0.0008
3.8126287060824247
6.693872782074528
→ Model improved. Saving...
------------------------------
Epoch [26/300], Step [499/499], Loss: 0.0008
3.749201325904672
6.58482518366511
→ Model improved. Saving...
------------------------------
Epoch [27/300], Step [499/499], Loss: 0.0007
5.227381651755817
8.49533176846639
→ No improvement. Patience: 1/7
------------------------------
Epoch [28/300], Step [499/499], Loss: 0.0009
4.214664952583008
7.169646724500051
→ No improvement. Patience: 2/7
------------------------------
Epoch [29/300], Step [499/499], Loss: 0.0010
4.238367077916231
7.194185120486578
→ No improvement. Patience: 3/7
------------------------------
Epoch [30/300], Step [499/499], Loss: 0.0008
4.500839300385723
7.543463053400378
→ No improvement. Patience: 4/7
------------------------------
Epoch [31/300], Step [499/499], Loss: 0.0008
4.1277193520153315
7.031561724390577
→ No improvement. Patience: 5/7
------------------------------
Epoch [32/300], Step [499/499], Loss: 0.0006
3.72758742472357
6.516785644132514
→ Model improved. Saving...
------------------------------
Epoch [33/300], Step [499/499], Loss: 0.0006
3.5364209032390392
6.291643445531216
→ Model improved. Saving...
------------------------------
Epoch [34/300], Step [499/499], Loss: 0.0006
3.3909796365249196
6.104630761289614
→ Model improved. Saving...
------------------------------
Epoch [35/300], Step [499/499], Loss: 0.0006
3.3937987440904727
6.113867756612155
→ No improvement. Patience: 1/7
------------------------------
Epoch [36/300], Step [499/499], Loss: 0.0006
3.4874363042842025
6.218568780295608
→ No improvement. Patience: 2/7
------------------------------
Epoch [37/300], Step [499/499], Loss: 0.0006
3.3239927390533843
6.019259213314005
→ Model improved. Saving...
------------------------------
Epoch [38/300], Step [499/499], Loss: 0.0006
3.2585034607329058
5.907597881394719
→ Model improved. Saving...
------------------------------
Epoch [39/300], Step [499/499], Loss: 0.0006
3.290655382116414
5.937505823725573
→ No improvement. Patience: 1/7
------------------------------
Epoch [40/300], Step [499/499], Loss: 0.0007
3.8278496025876168
6.602062961987543
→ No improvement. Patience: 2/7
------------------------------
Epoch [41/300], Step [499/499], Loss: 0.0006
4.118060182921453
6.955848840708502
→ No improvement. Patience: 3/7
------------------------------
Epoch [42/300], Step [499/499], Loss: 0.0007
4.0142990174655155
6.784757034104079
→ No improvement. Patience: 4/7
------------------------------
Epoch [43/300], Step [499/499], Loss: 0.0011
5.7682792416963595
9.104790200187349
→ No improvement. Patience: 5/7
------------------------------
Epoch [44/300], Step [499/499], Loss: 0.0007
6.609440156488561
10.232531029217494
→ No improvement. Patience: 6/7
------------------------------
Epoch [45/300], Step [499/499], Loss: 0.0007
5.172477531761566
8.314565063410294
→ No improvement. Patience: 7/7
Early stopping triggered.
parameter sava...epoch:44 batch_size64 lr:0.0001 kernel_size7 stride:1 train_acc:3.2585034607329058 test_acc:5.907597881394719
Best model parameters loaded: ./model/27la.pth
Best model parameters loaded../model/27la.pth










After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 17.50 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 16.30 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.55 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.74 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 15.86 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 14.56 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.39 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 14.28 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.05 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 16.93 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 15.46 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.60 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.45 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 15.77 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 14.93 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.07 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 13.95 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.01 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 16.20 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 16.10 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.76 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.91 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 15.94 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 15.55 meters
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
After Conv1: 21 x 21
After Pool2: 10 x 10
After Conv3: 8 x 8
After Pool4: 4 x 4
Test set average Euclidean distance: 15.27 meters
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
After Conv1: 19 x 19
After Pool2: 9 x 9
After Conv3: 5 x 5
After Pool4: 2 x 2
Test set average Euclidean distance: 15.56 meters
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
After Conv1: 17 x 17
After Pool2: 8 x 8
After Conv3: 2 x 2
After Pool4: 1 x 1
Test set average Euclidean distance: 14.65 meters


